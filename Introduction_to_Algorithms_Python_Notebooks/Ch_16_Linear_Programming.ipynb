{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Simplex Algorithm"
      ],
      "metadata": {
        "id": "N4ONFQOzcD9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWKsP7kXb38b"
      },
      "outputs": [],
      "source": [
        "def simplex_algorithm(A, b, c):\n",
        "    \"\"\"\n",
        "    Solves the linear programming problem using the Simplex algorithm.\n",
        "\n",
        "    Args:\n",
        "        A (list of list of float): The matrix representing the coefficients of the constraints.\n",
        "        b (list of float): The vector representing the right-hand side of the constraints.\n",
        "        c (list of float): The vector representing the coefficients of the objective function.\n",
        "\n",
        "    Returns:\n",
        "        list of list of float: The final tableau after optimization.\n",
        "    \"\"\"\n",
        "    # Initialize tableau\n",
        "    tableau = initialize_tableau(A, b, c)\n",
        "    while any(coef < 0 for coef in tableau[0]):\n",
        "        # Select entering variable\n",
        "        entering_variable = select_entering_variable(tableau[0])\n",
        "        # Select leaving variable\n",
        "        leaving_variable = select_leaving_variable(tableau, entering_variable)\n",
        "        # Update tableau\n",
        "        tableau = update_tableau(tableau, entering_variable, leaving_variable)\n",
        "    return tableau\n",
        "\n",
        "def initialize_tableau(A, b, c):\n",
        "    \"\"\"\n",
        "    Initializes the tableau for the Simplex algorithm.\n",
        "\n",
        "    Args:\n",
        "        A (list of list of float): The matrix representing the coefficients of the constraints.\n",
        "        b (list of float): The vector representing the right-hand side of the constraints.\n",
        "        c (list of float): The vector representing the coefficients of the objective function.\n",
        "\n",
        "    Returns:\n",
        "        list of list of float: The initialized tableau.\n",
        "    \"\"\"\n",
        "    # Create an identity matrix for the slack variables\n",
        "    slack_vars = [[0] * len(A) for _ in range(len(A))]\n",
        "    for i in range(len(A)):\n",
        "        slack_vars[i][i] = 1\n",
        "\n",
        "    # Combine A and slack_vars to form the tableau\n",
        "    tableau = [row_a + row_s + [bi] for row_a, row_s, bi in zip(A, slack_vars, b)]\n",
        "    # Append the objective function row\n",
        "    tableau.append([-ci for ci in c] + [0] * (len(A) + 1))\n",
        "\n",
        "    return tableau\n",
        "\n",
        "def select_entering_variable(objective_row):\n",
        "    \"\"\"\n",
        "    Selects the entering variable using the most negative coefficient in the objective row.\n",
        "\n",
        "    Args:\n",
        "        objective_row (list of float): The objective row of the tableau.\n",
        "\n",
        "    Returns:\n",
        "        int: The index of the entering variable.\n",
        "    \"\"\"\n",
        "    min_value = min(objective_row)\n",
        "    return objective_row.index(min_value)\n",
        "\n",
        "def select_leaving_variable(tableau, entering_variable):\n",
        "    \"\"\"\n",
        "    Selects the leaving variable using the minimum ratio test.\n",
        "\n",
        "    Args:\n",
        "        tableau (list of list of float): The current tableau.\n",
        "        entering_variable (int): The index of the entering variable.\n",
        "\n",
        "    Returns:\n",
        "        int: The index of the leaving variable.\n",
        "    \"\"\"\n",
        "    ratios = []\n",
        "    for row in tableau[:-1]:\n",
        "        if row[entering_variable] > 0:\n",
        "            ratios.append(row[-1] / row[entering_variable])\n",
        "        else:\n",
        "            ratios.append(float('inf'))\n",
        "    return ratios.index(min(ratios))\n",
        "\n",
        "def update_tableau(tableau, entering_variable, leaving_variable):\n",
        "    \"\"\"\n",
        "    Updates the tableau for the Simplex algorithm.\n",
        "\n",
        "    Args:\n",
        "        tableau (list of list of float): The current tableau.\n",
        "        entering_variable (int): The index of the entering variable.\n",
        "        leaving_variable (int): The index of the leaving variable.\n",
        "\n",
        "    Returns:\n",
        "        list of list of float: The updated tableau.\n",
        "    \"\"\"\n",
        "    new_tableau = [row[:] for row in tableau]\n",
        "    pivot = tableau[leaving_variable][entering_variable]\n",
        "\n",
        "    # Divide the leaving row by the pivot element\n",
        "    new_tableau[leaving_variable] = [x / pivot for x in tableau[leaving_variable]]\n",
        "\n",
        "    # Update the rest of the tableau\n",
        "    for i in range(len(tableau)):\n",
        "        if i != leaving_variable:\n",
        "            ratio = tableau[i][entering_variable] / pivot\n",
        "            new_tableau[i] = [x - ratio * y for x, y in zip(tableau[i], new_tableau[leaving_variable])]\n",
        "\n",
        "    return new_tableau\n",
        "\n",
        "# Example usage:\n",
        "A = [[2, 1], [1, 2]]\n",
        "b = [20, 20]\n",
        "c = [10, 12]\n",
        "final_tableau = simplex_algorithm(A, b, c)\n",
        "print(\"Final Tableau:\")\n",
        "for row in final_tableau:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ellipsoid Algorithm"
      ],
      "metadata": {
        "id": "1eQPCgFFcWqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def ellipsoid(A, b, c, epsilon):\n",
        "    \"\"\"\n",
        "    Solves the linear programming problem using the Ellipsoid method.\n",
        "\n",
        "    Args:\n",
        "        A (numpy.ndarray): The matrix representing the coefficients of the constraints.\n",
        "        b (numpy.ndarray): The vector representing the right-hand side of the constraints.\n",
        "        c (numpy.ndarray): The vector representing the coefficients of the objective function.\n",
        "        epsilon (float): The desired accuracy for the solution.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The optimal solution.\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    # Initialize ellipsoid containing the feasible region\n",
        "    E = Ellipsoid(np.zeros(n), np.eye(n))\n",
        "    while E.volume() > epsilon:\n",
        "        # Compute the center of the ellipsoid\n",
        "        x_k = E.center()\n",
        "        # Check if the current center is feasible\n",
        "        if np.all(np.dot(A, x_k) <= b):\n",
        "            return x_k  # Return optimal solution\n",
        "        else:\n",
        "            # Compute a separating hyperplane between x_k and the feasible region\n",
        "            hyperplane_normal = np.dot(A.T, np.linalg.solve(np.dot(A, np.dot(E.C, A.T)), np.dot(A, x_k) - b))\n",
        "            # Update the ellipsoid based on the separating hyperplane\n",
        "            E.update(hyperplane_normal)\n",
        "    return E.center()\n",
        "\n",
        "class Ellipsoid:\n",
        "    def __init__(self, center, C):\n",
        "        \"\"\"\n",
        "        Initializes an ellipsoid with a given center and shape matrix.\n",
        "\n",
        "        Args:\n",
        "            center (numpy.ndarray): The center of the ellipsoid.\n",
        "            C (numpy.ndarray): The shape matrix of the ellipsoid.\n",
        "        \"\"\"\n",
        "        self.center = center\n",
        "        self.C = C\n",
        "\n",
        "    def volume(self):\n",
        "        \"\"\"\n",
        "        Calculates the volume of the ellipsoid.\n",
        "\n",
        "        Returns:\n",
        "            float: The volume of the ellipsoid.\n",
        "        \"\"\"\n",
        "        return np.pi ** (self.C.shape[0] / 2) / np.sqrt(np.linalg.det(self.C))\n",
        "\n",
        "    def update(self, normal):\n",
        "        \"\"\"\n",
        "        Updates the ellipsoid based on a separating hyperplane.\n",
        "\n",
        "        Args:\n",
        "            normal (numpy.ndarray): The normal vector of the separating hyperplane.\n",
        "        \"\"\"\n",
        "        self.center += np.dot(np.linalg.inv(self.C), normal / np.linalg.norm(normal))\n",
        "        self.C = self.C / np.linalg.norm(normal) ** 2\n",
        "\n",
        "    def center(self):\n",
        "        \"\"\"\n",
        "        Returns the center of the ellipsoid.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: The center of the ellipsoid.\n",
        "        \"\"\"\n",
        "        return self.center\n",
        "\n",
        "# Example usage\n",
        "A = np.array([[2, 1], [1, 2]])\n",
        "b = np.array([4, 5])\n",
        "c = np.array([-3, -5])\n",
        "epsilon = 1e-6\n",
        "optimal_solution = ellipsoid(A, b, c, epsilon)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "ECuLL2xscXBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revised Simplex Method"
      ],
      "metadata": {
        "id": "In7Zgkz6coPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def revised_simplex(A, b, c):\n",
        "    \"\"\"\n",
        "    Solves the linear programming problem using the revised simplex method.\n",
        "\n",
        "    Args:\n",
        "        A (numpy.ndarray): The matrix representing the coefficients of the constraints.\n",
        "        b (numpy.ndarray): The vector representing the right-hand side of the constraints.\n",
        "        c (numpy.ndarray): The vector representing the coefficients of the objective function.\n",
        "\n",
        "    Returns:\n",
        "        tuple: The objective value and the optimal solution.\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    # Initialize basic feasible solution\n",
        "    B = np.eye(m)\n",
        "    N = np.eye(n)\n",
        "    x_B = np.zeros(m)\n",
        "    x_N = np.linalg.solve(B, b)\n",
        "    while np.any(c @ N - np.dot(x_N, A) < 0):\n",
        "        # Choose entering variable with negative reduced cost\n",
        "        enter_idx = np.argmax(c @ N - np.dot(x_N, A) < 0)\n",
        "        # Determine leaving variable using ratio test\n",
        "        ratios = np.divide(x_N, np.dot(B[:, enter_idx], A[:, enter_idx]))\n",
        "        leave_idx = np.argmin(ratios[ratios > 0])\n",
        "        leave_idx = np.where(ratios > 0)[leave_idx]\n",
        "        # Update basic solution\n",
        "        pivot_row = B[leave_idx, :]\n",
        "        pivot_col = A[:, enter_idx]\n",
        "        x_B[leave_idx] = b[leave_idx] / pivot_row @ pivot_col\n",
        "        B[leave_idx, :] = pivot_col / pivot_row @ B\n",
        "        N[enter_idx, :] = -pivot_col / pivot_row @ N\n",
        "        N[enter_idx, enter_idx] = 1 / pivot_row @ N\n",
        "        x_N = np.linalg.solve(B, b)\n",
        "    return c @ x_N, x_N\n",
        "\n",
        "# Example usage\n",
        "A = np.array([[2, 1], [1, 2], [1, -1]])\n",
        "b = np.array([4, 5, 1])\n",
        "c = np.array([-3, -5])\n",
        "objective_value, optimal_solution = revised_simplex(A, b, c)\n",
        "print(\"Objective value:\", objective_value)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "k6wOlftbcpBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Newton's Method"
      ],
      "metadata": {
        "id": "YJvNF-6nc0_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def newton_method(f, f_prime, x0, tol=1e-7, max_iter=100):\n",
        "    \"\"\"\n",
        "    Solves f(x) = 0 using Newton's method.\n",
        "\n",
        "    Args:\n",
        "        f (function): The function for which we want to find a root.\n",
        "        f_prime (function): The derivative of the function f.\n",
        "        x0 (float): Initial guess for the root.\n",
        "        tol (float): Tolerance for the convergence criterion. Defaults to 1e-7.\n",
        "        max_iter (int): Maximum number of iterations. Defaults to 100.\n",
        "\n",
        "    Returns:\n",
        "        float: The estimated root.\n",
        "        int: The number of iterations performed.\n",
        "    \"\"\"\n",
        "    x = x0\n",
        "    for i in range(max_iter):\n",
        "        fx = f(x)\n",
        "        fpx = f_prime(x)\n",
        "        if fpx == 0:\n",
        "            raise ValueError(\"Derivative is zero. No solution found.\")\n",
        "\n",
        "        # Compute the next approximation\n",
        "        x_new = x - fx / fpx\n",
        "\n",
        "        # Check for convergence\n",
        "        if abs(x_new - x) < tol:\n",
        "            return x_new, i + 1\n",
        "\n",
        "        # Update the current approximation\n",
        "        x = x_new\n",
        "\n",
        "    raise ValueError(\"Maximum number of iterations reached. No solution found.\")\n",
        "\n",
        "# Example usage\n",
        "def f(x):\n",
        "    return x**2 - 2  # Example function: f(x) = x^2 - 2\n",
        "\n",
        "def f_prime(x):\n",
        "    return 2 * x  # Derivative: f'(x) = 2x\n",
        "\n",
        "x0 = 1.0  # Initial guess\n",
        "root, iterations = newton_method(f, f_prime, x0)\n",
        "print(\"Estimated root:\", root)\n",
        "print(\"Iterations:\", iterations)"
      ],
      "metadata": {
        "id": "zkbo3z9lc1Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Barrier Method"
      ],
      "metadata": {
        "id": "uzFFLLsOc78i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def barrier_method(f, grad_f, hess_f, constraints, x0, t=1.0, mu=10, tol=1e-7, max_iter=100):\n",
        "    \"\"\"\n",
        "    Solves a constrained optimization problem using the Barrier method.\n",
        "\n",
        "    Args:\n",
        "        f (function): The objective function to minimize.\n",
        "        grad_f (function): The gradient of the objective function.\n",
        "        hess_f (function): The Hessian of the objective function.\n",
        "        constraints (list): A list of constraint functions g_i(x) <= 0.\n",
        "        x0 (numpy.ndarray): Initial guess for the variables.\n",
        "        t (float): Initial barrier parameter.\n",
        "        mu (float): Factor by which to increase t.\n",
        "        tol (float): Tolerance for the convergence criterion.\n",
        "        max_iter (int): Maximum number of iterations.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The estimated solution.\n",
        "    \"\"\"\n",
        "    def barrier_function(x, t):\n",
        "        penalty = 0\n",
        "        for g in constraints:\n",
        "            penalty += -np.log(-g(x))\n",
        "        return t * f(x) + penalty\n",
        "\n",
        "    def barrier_grad(x, t):\n",
        "        penalty_grad = np.zeros_like(x)\n",
        "        for g in constraints:\n",
        "            penalty_grad += grad_f(x) / -g(x)\n",
        "        return t * grad_f(x) + penalty_grad\n",
        "\n",
        "    def barrier_hess(x, t):\n",
        "        penalty_hess = np.zeros((x.shape[0], x.shape[0]))\n",
        "        for g in constraints:\n",
        "            grad_g = grad_f(x) / -g(x)\n",
        "            penalty_hess += np.outer(grad_g, grad_g) / g(x)\n",
        "        return t * hess_f(x) + penalty_hess\n",
        "\n",
        "    x = x0\n",
        "    for i in range(max_iter):\n",
        "        result = minimize(barrier_function, x, args=(t), jac=barrier_grad, hess=barrier_hess, method='trust-constr')\n",
        "        x = result.x\n",
        "        if len(constraints) / t < tol:\n",
        "            break\n",
        "        t *= mu\n",
        "\n",
        "    return x\n",
        "\n",
        "# Example usage\n",
        "def f(x):\n",
        "    return x[0]**2 + x[1]**2  # Example objective function\n",
        "\n",
        "def grad_f(x):\n",
        "    return np.array([2*x[0], 2*x[1]])  # Gradient of the objective function\n",
        "\n",
        "def hess_f(x):\n",
        "    return np.array([[2, 0], [0, 2]])  # Hessian of the objective function\n",
        "\n",
        "def g1(x):\n",
        "    return x[0] + x[1] - 1  # Example constraint: x[0] + x[1] <= 1\n",
        "\n",
        "def g2(x):\n",
        "    return -x[0]  # Example constraint: x[0] >= 0\n",
        "\n",
        "def g3(x):\n",
        "    return -x[1]  # Example constraint: x[1] >= 0\n",
        "\n",
        "constraints = [g1, g2, g3]\n",
        "x0 = np.array([0.5, 0.5])  # Initial guess\n",
        "\n",
        "optimal_solution = barrier_method(f, grad_f, hess_f, constraints, x0)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "IE62jo9ec8SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Path-following Method"
      ],
      "metadata": {
        "id": "CEgteGKadW9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def path_following_method(f, grad_f, hess_f, constraints, x0, tol=1e-7, max_iter=100):\n",
        "    \"\"\"\n",
        "    Solves a constrained optimization problem using the Path-following method.\n",
        "\n",
        "    Args:\n",
        "        f (function): The objective function to minimize.\n",
        "        grad_f (function): The gradient of the objective function.\n",
        "        hess_f (function): The Hessian of the objective function.\n",
        "        constraints (list): A list of constraint functions g_i(x) <= 0.\n",
        "        x0 (numpy.ndarray): Initial guess for the variables.\n",
        "        tol (float): Tolerance for the convergence criterion.\n",
        "        max_iter (int): Maximum number of iterations.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The estimated solution.\n",
        "    \"\"\"\n",
        "    def barrier_function(x, t):\n",
        "        penalty = 0\n",
        "        for g in constraints:\n",
        "            penalty += -np.log(-g(x))\n",
        "        return t * f(x) + penalty\n",
        "\n",
        "    def barrier_grad(x, t):\n",
        "        penalty_grad = np.zeros_like(x)\n",
        "        for g in constraints:\n",
        "            penalty_grad += grad_f(x) / -g(x)\n",
        "        return t * grad_f(x) + penalty_grad\n",
        "\n",
        "    def barrier_hess(x, t):\n",
        "        penalty_hess = np.zeros((x.shape[0], x.shape[0]))\n",
        "        for g in constraints:\n",
        "            grad_g = grad_f(x) / -g(x)\n",
        "            penalty_hess += np.outer(grad_g, grad_g) / g(x)\n",
        "        return t * hess_f(x) + penalty_hess\n",
        "\n",
        "    x = x0\n",
        "    t = 1.0  # Start with an initial barrier parameter\n",
        "    mu = 10  # Update factor for the barrier parameter\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        result = minimize(barrier_function, x, args=(t), jac=barrier_grad, hess=barrier_hess, method='trust-constr')\n",
        "        x = result.x\n",
        "        if np.linalg.norm(result.jac) < tol:\n",
        "            break\n",
        "        t *= mu  # Increase the barrier parameter\n",
        "\n",
        "    return x\n",
        "\n",
        "# Example usage\n",
        "def f(x):\n",
        "    return x[0]**2 + x[1]**2  # Example objective function\n",
        "\n",
        "def grad_f(x):\n",
        "    return np.array([2*x[0], 2*x[1]])  # Gradient of the objective function\n",
        "\n",
        "def hess_f(x):\n",
        "    return np.array([[2, 0], [0, 2]])  # Hessian of the objective function\n",
        "\n",
        "def g1(x):\n",
        "    return x[0] + x[1] - 1  # Example constraint: x[0] + x[1] <= 1\n",
        "\n",
        "def g2(x):\n",
        "    return -x[0]  # Example constraint: x[0] >= 0\n",
        "\n",
        "def g3(x):\n",
        "    return -x[1]  # Example constraint: x[1] >= 0\n",
        "\n",
        "constraints = [g1, g2, g3]\n",
        "x0 = np.array([0.5, 0.5])  # Initial guess\n",
        "\n",
        "optimal_solution = path_following_method(f, grad_f, hess_f, constraints, x0)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "bEPZEif4dXUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gomory's Method"
      ],
      "metadata": {
        "id": "7743RmzBdac_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def gomory_method(A, b, c):\n",
        "    \"\"\"\n",
        "    Solves a linear programming problem using Gomory's cutting plane method.\n",
        "\n",
        "    Args:\n",
        "        A (numpy.ndarray): Coefficient matrix.\n",
        "        b (numpy.ndarray): Right-hand side vector.\n",
        "        c (numpy.ndarray): Cost vector.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The optimal solution.\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    bounds = [(0, None) for _ in range(n)]\n",
        "\n",
        "    while True:\n",
        "        # Solve the current LP relaxation\n",
        "        res = linprog(c, A_eq=A, b_eq=b, bounds=bounds, method='simplex')\n",
        "        x = res.x\n",
        "\n",
        "        # Check if the solution is integer\n",
        "        if np.allclose(x, np.round(x)):\n",
        "            return np.round(x)\n",
        "\n",
        "        # Find the most fractional variable\n",
        "        fractional_indices = np.where(np.abs(x - np.round(x)) > 1e-5)[0]\n",
        "        if len(fractional_indices) == 0:\n",
        "            return x  # No fractional variables found, return the solution\n",
        "\n",
        "        # Add a Gomory cut\n",
        "        i = fractional_indices[0]\n",
        "        frac_part = x[i] - np.floor(x[i])\n",
        "        new_row = np.floor(A[i]) - A[i]\n",
        "        new_b = frac_part - np.floor(x[i])\n",
        "\n",
        "        A = np.vstack([A, new_row])\n",
        "        b = np.append(b, new_b)\n",
        "\n",
        "# Example usage\n",
        "A = np.array([[1, 1], [2, 1]])\n",
        "b = np.array([4, 5])\n",
        "c = np.array([-3, -4])\n",
        "\n",
        "optimal_solution = gomory_method(A, b, c)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "AjpoAcPZdbLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chvátal-Gomory Cutting Plane Method"
      ],
      "metadata": {
        "id": "_GXiNb9TdpBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def chvatal_gomory_cutting_plane(A, b, c):\n",
        "    \"\"\"\n",
        "    Solves a linear programming problem using the Chvátal-Gomory cutting plane method.\n",
        "\n",
        "    Args:\n",
        "        A (numpy.ndarray): Coefficient matrix.\n",
        "        b (numpy.ndarray): Right-hand side vector.\n",
        "        c (numpy.ndarray): Cost vector.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The optimal solution.\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    bounds = [(0, None) for _ in range(n)]\n",
        "\n",
        "    while True:\n",
        "        # Solve the current LP relaxation\n",
        "        res = linprog(c, A_eq=A, b_eq=b, bounds=bounds, method='simplex')\n",
        "        x = res.x\n",
        "\n",
        "        # Check if the solution is integer\n",
        "        if np.allclose(x, np.round(x)):\n",
        "            return np.round(x)\n",
        "\n",
        "        # Find the most fractional row in the constraint matrix\n",
        "        fractional_rows = [i for i in range(len(b)) if not np.isclose(b[i], np.round(b[i]))]\n",
        "        if not fractional_rows:\n",
        "            return x  # No fractional constraints found, return the solution\n",
        "\n",
        "        # Add a Chvátal-Gomory cut\n",
        "        i = fractional_rows[0]\n",
        "        new_row = np.floor(A[i]) - A[i]\n",
        "        new_b = np.floor(b[i])\n",
        "\n",
        "        A = np.vstack([A, new_row])\n",
        "        b = np.append(b, new_b)\n",
        "\n",
        "# Example usage\n",
        "A = np.array([[1, 1], [2, 1]])\n",
        "b = np.array([4, 5])\n",
        "c = np.array([-3, -4])\n",
        "\n",
        "optimal_solution = chvatal_gomory_cutting_plane(A, b, c)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "x1Hq_tkadpZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lift-and-Project Method"
      ],
      "metadata": {
        "id": "Eaar7YcSd-Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def lift_and_project(A, b, c, max_iterations=100, tol=1e-6):\n",
        "    \"\"\"\n",
        "    Solves a linear programming problem using the Lift-and-Project method.\n",
        "\n",
        "    Args:\n",
        "        A (numpy.ndarray): Coefficient matrix.\n",
        "        b (numpy.ndarray): Right-hand side vector.\n",
        "        c (numpy.ndarray): Cost vector.\n",
        "        max_iterations (int): Maximum number of iterations.\n",
        "        tol (float): Tolerance for checking integrality.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The optimal solution.\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    bounds = [(0, None) for _ in range(n)]\n",
        "    A_ = np.copy(A)\n",
        "    b_ = np.copy(b)\n",
        "\n",
        "    for iteration in range(max_iterations):\n",
        "        # Solve the current LP relaxation\n",
        "        res = linprog(c, A_eq=A_, b_eq=b_, bounds=bounds, method='simplex')\n",
        "        x = res.x\n",
        "\n",
        "        # Check if the solution is integer\n",
        "        if np.allclose(x, np.round(x), atol=tol):\n",
        "            return np.round(x)\n",
        "\n",
        "        # Find the most fractional variable\n",
        "        fractional_vars = [i for i in range(n) if not np.isclose(x[i], np.round(x[i]), atol=tol)]\n",
        "        if not fractional_vars:\n",
        "            return x  # No fractional variables found, return the solution\n",
        "\n",
        "        # Lift-and-Project: Add new constraints to eliminate the current fractional solution\n",
        "        i = fractional_vars[0]\n",
        "        floor_xi = np.floor(x[i])\n",
        "        ceil_xi = np.ceil(x[i])\n",
        "\n",
        "        # Create new rows for the lift-and-project cuts\n",
        "        new_row_1 = np.zeros(n)\n",
        "        new_row_2 = np.zeros(n)\n",
        "\n",
        "        new_row_1[i] = 1\n",
        "        new_row_2[i] = -1\n",
        "\n",
        "        A_ = np.vstack([A_, new_row_1, new_row_2])\n",
        "        b_ = np.append(b_, floor_xi, -ceil_xi)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Example usage\n",
        "A = np.array([[1, 1], [2, 1]])\n",
        "b = np.array([4, 5])\n",
        "c = np.array([-3, -4])\n",
        "\n",
        "optimal_solution = lift_and_project(A, b, c)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "G4BPQw5Ud-3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stochastic Linear Programming"
      ],
      "metadata": {
        "id": "aJ7aqbNXeODl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def sample_scenarios(num_scenarios, A_stochastic, b_stochastic):\n",
        "    \"\"\"\n",
        "    Generate sample scenarios for the stochastic elements of A and b.\n",
        "\n",
        "    Args:\n",
        "        num_scenarios (int): Number of scenarios to generate.\n",
        "        A_stochastic (list of tuples): List of tuples representing the stochastic part of A.\n",
        "        b_stochastic (list of tuples): List of tuples representing the stochastic part of b.\n",
        "\n",
        "    Returns:\n",
        "        list of numpy.ndarray: Sampled scenarios for A.\n",
        "        list of numpy.ndarray: Sampled scenarios for b.\n",
        "    \"\"\"\n",
        "    A_scenarios = []\n",
        "    b_scenarios = []\n",
        "\n",
        "    for _ in range(num_scenarios):\n",
        "        A_scenario = np.zeros_like(A_stochastic[0][0])\n",
        "        for (mean, std) in A_stochastic:\n",
        "            A_scenario += np.random.normal(mean, std)\n",
        "        A_scenarios.append(A_scenario)\n",
        "\n",
        "        b_scenario = np.zeros_like(b_stochastic[0][0])\n",
        "        for (mean, std) in b_stochastic:\n",
        "            b_scenario += np.random.normal(mean, std)\n",
        "        b_scenarios.append(b_scenario)\n",
        "\n",
        "    return A_scenarios, b_scenarios\n",
        "\n",
        "def stochastic_linear_programming(A_deterministic, b_deterministic, c, A_stochastic, b_stochastic, num_scenarios=100):\n",
        "    \"\"\"\n",
        "    Solve a stochastic linear programming problem using the sample average approximation method.\n",
        "\n",
        "    Args:\n",
        "        A_deterministic (numpy.ndarray): Deterministic part of the coefficient matrix A.\n",
        "        b_deterministic (numpy.ndarray): Deterministic part of the right-hand side vector b.\n",
        "        c (numpy.ndarray): Cost vector.\n",
        "        A_stochastic (list of tuples): List of tuples representing the stochastic part of A.\n",
        "        b_stochastic (list of tuples): List of tuples representing the stochastic part of b.\n",
        "        num_scenarios (int): Number of scenarios to generate.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The optimal solution.\n",
        "    \"\"\"\n",
        "    m, n = A_deterministic.shape\n",
        "    A_scenarios, b_scenarios = sample_scenarios(num_scenarios, A_stochastic, b_stochastic)\n",
        "\n",
        "    # Initialize the expected value of the constraint matrix and right-hand side vector\n",
        "    A_expected = np.copy(A_deterministic)\n",
        "    b_expected = np.copy(b_deterministic)\n",
        "\n",
        "    for A_scenario, b_scenario in zip(A_scenarios, b_scenarios):\n",
        "        A_expected += A_scenario\n",
        "        b_expected += b_scenario\n",
        "\n",
        "    # Average the scenarios to approximate the expected values\n",
        "    A_expected /= num_scenarios\n",
        "    b_expected /= num_scenarios\n",
        "\n",
        "    # Solve the approximated deterministic linear program\n",
        "    res = linprog(c, A_eq=A_expected, b_eq=b_expected, method='simplex')\n",
        "    return res.x\n",
        "\n",
        "# Example usage\n",
        "A_deterministic = np.array([[1, 1], [2, 1]])\n",
        "b_deterministic = np.array([4, 5])\n",
        "c = np.array([-3, -4])\n",
        "A_stochastic = [(np.array([[0.1, 0.1], [0.2, 0.2]]), np.array([[0.01, 0.01], [0.02, 0.02]]))]\n",
        "b_stochastic = [(np.array([0.1, 0.2]), np.array([0.01, 0.02]))]\n",
        "\n",
        "optimal_solution = stochastic_linear_programming(A_deterministic, b_deterministic, c, A_stochastic, b_stochastic)\n",
        "print(\"Optimal solution:\", optimal_solution)"
      ],
      "metadata": {
        "id": "omBt8S-SeOag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-objective Linear Programming"
      ],
      "metadata": {
        "id": "i7PkdQdseZQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import linprog\n",
        "\n",
        "def weighted_sum_method(A, b, c_list, weights):\n",
        "    \"\"\"\n",
        "    Solve a multi-objective linear programming problem using the weighted sum method.\n",
        "\n",
        "    Args:\n",
        "        A (numpy.ndarray): Coefficient matrix.\n",
        "        b (numpy.ndarray): Right-hand side vector.\n",
        "        c_list (list of numpy.ndarray): List of cost vectors for each objective.\n",
        "        weights (list of float): Weights for each objective.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: The optimal solution.\n",
        "        float: The optimal weighted objective value.\n",
        "    \"\"\"\n",
        "    # Validate input dimensions\n",
        "    num_objectives = len(c_list)\n",
        "    if num_objectives != len(weights):\n",
        "        raise ValueError(\"The number of cost vectors and weights must be the same.\")\n",
        "\n",
        "    # Compute the weighted sum of the cost vectors\n",
        "    c_weighted = np.zeros_like(c_list[0])\n",
        "    for c, w in zip(c_list, weights):\n",
        "        c_weighted += w * c\n",
        "\n",
        "    # Solve the single-objective linear program with the weighted cost vector\n",
        "    res = linprog(c_weighted, A_eq=A, b_eq=b, method='simplex')\n",
        "    return res.x, res.fun\n",
        "\n",
        "# Example usage\n",
        "A = np.array([[1, 2], [4, 0], [0, 4]])\n",
        "b = np.array([8, 16, 12])\n",
        "c_list = [np.array([1, 1]), np.array([2, 3])]\n",
        "weights = [0.5, 0.5]\n",
        "\n",
        "optimal_solution, optimal_value = weighted_sum_method(A, b, c_list, weights)\n",
        "print(\"Optimal solution:\", optimal_solution)\n",
        "print(\"Optimal weighted objective value:\", optimal_value)"
      ],
      "metadata": {
        "id": "jxt-CcAMeZkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vehicle Routing Problem using Linear Programming"
      ],
      "metadata": {
        "id": "HQxA0RMmemGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pulp\n",
        "import numpy as np\n",
        "\n",
        "def solve_vrp(num_vehicles, vehicle_capacity, demands, distance_matrix):\n",
        "    num_customers = len(demands) - 1  # excluding the depot\n",
        "\n",
        "    # Create the problem variable\n",
        "    prob = pulp.LpProblem(\"VRP\", pulp.LpMinimize)\n",
        "\n",
        "    # Decision variables\n",
        "    x = pulp.LpVariable.dicts(\"x\", [(i, j, k) for i in range(num_customers + 1) for j in range(num_customers + 1) for k in range(num_vehicles)], 0, 1, pulp.LpBinary)\n",
        "    u = pulp.LpVariable.dicts(\"u\", (i for i in range(1, num_customers + 1)), 0, vehicle_capacity, pulp.LpContinuous)\n",
        "\n",
        "    # Objective function: minimize the total distance traveled\n",
        "    prob += pulp.lpSum(distance_matrix[i][j] * x[i, j, k] for i in range(num_customers + 1) for j in range(num_customers + 1) for k in range(num_vehicles))\n",
        "\n",
        "    # Constraints\n",
        "    # Each customer is visited exactly once by exactly one vehicle\n",
        "    for j in range(1, num_customers + 1):\n",
        "        prob += pulp.lpSum(x[i, j, k] for i in range(num_customers + 1) for k in range(num_vehicles)) == 1\n",
        "\n",
        "    # Each vehicle starts from the depot\n",
        "    for k in range(num_vehicles):\n",
        "        prob += pulp.lpSum(x[0, j, k] for j in range(1, num_customers + 1)) == 1\n",
        "\n",
        "    # Each vehicle returns to the depot\n",
        "    for k in range(num_vehicles):\n",
        "        prob += pulp.lpSum(x[i, 0, k] for i in range(1, num_customers + 1)) == 1\n",
        "\n",
        "    # Flow constraints\n",
        "    for k in range(num_vehicles):\n",
        "        for i in range(num_customers + 1):\n",
        "            prob += pulp.lpSum(x[i, j, k] for j in range(num_customers + 1)) - pulp.lpSum(x[j, i, k] for j in range(num_customers + 1)) == 0\n",
        "\n",
        "    # Subtour elimination constraints\n",
        "    for k in range(num_vehicles):\n",
        "        for i in range(1, num_customers + 1):\n",
        "            for j in range(1, num_customers + 1):\n",
        "                if i != j:\n",
        "                    prob += u[i] - u[j] + vehicle_capacity * x[i, j, k] <= vehicle_capacity - demands[j]\n",
        "\n",
        "    # Solve the problem\n",
        "    prob.solve()\n",
        "\n",
        "    # Get the results\n",
        "    routes = []\n",
        "    for k in range(num_vehicles):\n",
        "        route = []\n",
        "        i = 0\n",
        "        while True:\n",
        "            for j in range(num_customers + 1):\n",
        "                if x[i, j, k].varValue > 0.5:\n",
        "                    route.append(j)\n",
        "                    i = j\n",
        "                    break\n",
        "            if i == 0:\n",
        "                break\n",
        "        routes.append(route)\n",
        "\n",
        "    return routes\n",
        "\n",
        "# Example usage\n",
        "num_vehicles = 2\n",
        "vehicle_capacity = 15\n",
        "demands = [0, 4, 6, 7, 3, 5]  # Including the depot with demand 0\n",
        "distance_matrix = [\n",
        "    [0, 10, 15, 20, 25, 30],\n",
        "    [10, 0, 35, 25, 30, 40],\n",
        "    [15, 35, 0, 30, 20, 25],\n",
        "    [20, 25, 30, 0, 15, 10],\n",
        "    [25, 30, 20, 15, 0, 35],\n",
        "    [30, 40, 25, 10, 35, 0]\n",
        "]\n",
        "\n",
        "routes = solve_vrp(num_vehicles, vehicle_capacity, demands, distance_matrix)\n",
        "print(\"Routes:\", routes)\n"
      ],
      "metadata": {
        "id": "KExOpsOiemd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Financial Portfolio Optimization using Linear Programming"
      ],
      "metadata": {
        "id": "KvKh1tPzfDii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pulp\n",
        "import numpy as np\n",
        "\n",
        "def portfolio_optimization(expected_returns, cov_matrix, risk_tolerance):\n",
        "    n_assets = len(expected_returns)\n",
        "\n",
        "    # Create the problem variable\n",
        "    prob = pulp.LpProblem(\"Portfolio Optimization\", pulp.LpMaximize)\n",
        "\n",
        "    # Decision variables for asset weights\n",
        "    weights = pulp.LpVariable.dicts(\"weights\", range(n_assets), lowBound=0, upBound=1)\n",
        "\n",
        "    # Objective function: maximize expected return\n",
        "    prob += pulp.lpSum(expected_returns[i] * weights[i] for i in range(n_assets)), \"Expected Return\"\n",
        "\n",
        "    # Constraint: sum of weights equals 1 (fully invested portfolio)\n",
        "    prob += pulp.lpSum(weights[i] for i in range(n_assets)) == 1, \"Total Weight\"\n",
        "\n",
        "    # Constraint: portfolio variance should be less than or equal to risk tolerance\n",
        "    portfolio_variance = pulp.lpSum(weights[i] * weights[j] * cov_matrix[i][j] for i in range(n_assets) for j in range(n_assets))\n",
        "    prob += portfolio_variance <= risk_tolerance, \"Risk Constraint\"\n",
        "\n",
        "    # Solve the problem\n",
        "    prob.solve()\n",
        "\n",
        "    # Get the results\n",
        "    optimal_weights = np.array([pulp.value(weights[i]) for i in range(n_assets)])\n",
        "    return optimal_weights\n",
        "\n",
        "# Example usage\n",
        "expected_returns = [0.1, 0.2, 0.15]  # Example expected returns of assets\n",
        "cov_matrix = [[0.005, -0.010, 0.004], [-0.010, 0.040, -0.002], [0.004, -0.002, 0.023]]  # Example covariance matrix\n",
        "risk_tolerance = 0.005  # Maximum acceptable risk (variance)\n",
        "\n",
        "optimal_weights = portfolio_optimization(expected_returns, cov_matrix, risk_tolerance)\n",
        "print(\"Optimal Weights:\", optimal_weights)"
      ],
      "metadata": {
        "id": "77Z2PQAFfD7x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# First-Come, First-Served (FCFS) Scheduling"
      ],
      "metadata": {
        "id": "i73Mr-AT7bdl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_Ix_HOX7Or-"
      },
      "outputs": [],
      "source": [
        "class Process:\n",
        "    def __init__(self, pid, burst_time):\n",
        "        self.pid = pid\n",
        "        self.burst_time = burst_time\n",
        "        self.waiting_time = 0\n",
        "        self.turnaround_time = 0\n",
        "\n",
        "def fcfs_scheduling(processes):\n",
        "    \"\"\"\n",
        "    Function to perform First-Come, First-Served (FCFS) Scheduling.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None (modifies the processes list in place)\n",
        "    \"\"\"\n",
        "    n = len(processes)\n",
        "\n",
        "    # Calculate waiting time for each process\n",
        "    processes[0].waiting_time = 0\n",
        "    for i in range(1, n):\n",
        "        processes[i].waiting_time = processes[i - 1].waiting_time + processes[i - 1].burst_time\n",
        "\n",
        "    # Calculate turnaround time for each process\n",
        "    for i in range(n):\n",
        "        processes[i].turnaround_time = processes[i].waiting_time + processes[i].burst_time\n",
        "\n",
        "def print_scheduling_result(processes):\n",
        "    \"\"\"\n",
        "    Function to print the scheduling result.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    total_waiting_time = 0\n",
        "    total_turnaround_time = 0\n",
        "\n",
        "    print(\"PID\\tBurst Time\\tWaiting Time\\tTurnaround Time\")\n",
        "    for process in processes:\n",
        "        total_waiting_time += process.waiting_time\n",
        "        total_turnaround_time += process.turnaround_time\n",
        "        print(f\"{process.pid}\\t{process.burst_time}\\t\\t{process.waiting_time}\\t\\t{process.turnaround_time}\")\n",
        "\n",
        "    print(f\"\\nAverage Waiting Time: {total_waiting_time / len(processes):.2f}\")\n",
        "    print(f\"Average Turnaround Time: {total_turnaround_time / len(processes):.2f}\")\n",
        "\n",
        "# Example usage\n",
        "process_list = [Process(1, 5), Process(2, 8), Process(3, 12)]\n",
        "fcfs_scheduling(process_list)\n",
        "print_scheduling_result(process_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shortest Job First (SJF) Scheduling"
      ],
      "metadata": {
        "id": "M2yrEIqs7kCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Process:\n",
        "    def __init__(self, pid, burst_time):\n",
        "        self.pid = pid\n",
        "        self.burst_time = burst_time\n",
        "        self.waiting_time = 0\n",
        "        self.turnaround_time = 0\n",
        "\n",
        "def sjf_scheduling(processes):\n",
        "    \"\"\"\n",
        "    Function to perform Shortest Job First (SJF) Scheduling.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None (modifies the processes list in place)\n",
        "    \"\"\"\n",
        "    # Sort processes by burst time\n",
        "    processes.sort(key=lambda x: x.burst_time)\n",
        "\n",
        "    n = len(processes)\n",
        "\n",
        "    # Calculate waiting time for each process\n",
        "    processes[0].waiting_time = 0\n",
        "    for i in range(1, n):\n",
        "        processes[i].waiting_time = processes[i - 1].waiting_time + processes[i - 1].burst_time\n",
        "\n",
        "    # Calculate turnaround time for each process\n",
        "    for i in range(n):\n",
        "        processes[i].turnaround_time = processes[i].waiting_time + processes[i].burst_time\n",
        "\n",
        "def print_scheduling_result(processes):\n",
        "    \"\"\"\n",
        "    Function to print the scheduling result.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    total_waiting_time = 0\n",
        "    total_turnaround_time = 0\n",
        "\n",
        "    print(\"PID\\tBurst Time\\tWaiting Time\\tTurnaround Time\")\n",
        "    for process in processes:\n",
        "        total_waiting_time += process.waiting_time\n",
        "        total_turnaround_time += process.turnaround_time\n",
        "        print(f\"{process.pid}\\t{process.burst_time}\\t\\t{process.waiting_time}\\t\\t{process.turnaround_time}\")\n",
        "\n",
        "    print(f\"\\nAverage Waiting Time: {total_waiting_time / len(processes):.2f}\")\n",
        "    print(f\"Average Turnaround Time: {total_turnaround_time / len(processes):.2f}\")\n",
        "\n",
        "# Example usage\n",
        "process_list = [Process(1, 6), Process(2, 8), Process(3, 7), Process(4, 3)]\n",
        "sjf_scheduling(process_list)\n",
        "print_scheduling_result(process_list)"
      ],
      "metadata": {
        "id": "LhMxi9j37kfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Priority Scheduling"
      ],
      "metadata": {
        "id": "rKh9Ipzw7xwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Process:\n",
        "    def __init__(self, pid, burst_time, priority):\n",
        "        self.pid = pid\n",
        "        self.burst_time = burst_time\n",
        "        self.priority = priority\n",
        "        self.waiting_time = 0\n",
        "        self.turnaround_time = 0\n",
        "\n",
        "def priority_scheduling(processes):\n",
        "    \"\"\"\n",
        "    Function to perform Priority Scheduling.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None (modifies the processes list in place)\n",
        "    \"\"\"\n",
        "    # Sort processes by priority (higher priority first)\n",
        "    processes.sort(key=lambda x: x.priority, reverse=True)\n",
        "\n",
        "    n = len(processes)\n",
        "\n",
        "    # Calculate waiting time for each process\n",
        "    processes[0].waiting_time = 0\n",
        "    for i in range(1, n):\n",
        "        processes[i].waiting_time = processes[i - 1].waiting_time + processes[i - 1].burst_time\n",
        "\n",
        "    # Calculate turnaround time for each process\n",
        "    for i in range(n):\n",
        "        processes[i].turnaround_time = processes[i].waiting_time + processes[i].burst_time\n",
        "\n",
        "def print_scheduling_result(processes):\n",
        "    \"\"\"\n",
        "    Function to print the scheduling result.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    total_waiting_time = 0\n",
        "    total_turnaround_time = 0\n",
        "\n",
        "    print(\"PID\\tBurst Time\\tPriority\\tWaiting Time\\tTurnaround Time\")\n",
        "    for process in processes:\n",
        "        total_waiting_time += process.waiting_time\n",
        "        total_turnaround_time += process.turnaround_time\n",
        "        print(f\"{process.pid}\\t{process.burst_time}\\t\\t{process.priority}\\t\\t{process.waiting_time}\\t\\t{process.turnaround_time}\")\n",
        "\n",
        "    print(f\"\\nAverage Waiting Time: {total_waiting_time / len(processes):.2f}\")\n",
        "    print(f\"Average Turnaround Time: {total_turnaround_time / len(processes):.2f}\")\n",
        "\n",
        "# Example usage\n",
        "process_list = [Process(1, 10, 3), Process(2, 1, 1), Process(3, 2, 4), Process(4, 1, 5), Process(5, 5, 2)]\n",
        "priority_scheduling(process_list)\n",
        "print_scheduling_result(process_list)"
      ],
      "metadata": {
        "id": "DHE_TJ167ySi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round-Robin Scheduling"
      ],
      "metadata": {
        "id": "wRX1PraA799d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Process:\n",
        "    def __init__(self, pid, burst_time):\n",
        "        self.pid = pid\n",
        "        self.burst_time = burst_time\n",
        "        self.remaining_time = burst_time\n",
        "        self.waiting_time = 0\n",
        "        self.turnaround_time = 0\n",
        "\n",
        "def round_robin_scheduling(processes, time_quantum):\n",
        "    \"\"\"\n",
        "    Function to perform Round-Robin Scheduling.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "    time_quantum: Time quantum for Round-Robin Scheduling\n",
        "\n",
        "    Returns:\n",
        "    None (modifies the processes list in place)\n",
        "    \"\"\"\n",
        "    time = 0\n",
        "    queue = processes.copy()\n",
        "\n",
        "    while queue:\n",
        "        process = queue.pop(0)\n",
        "\n",
        "        if process.remaining_time > time_quantum:\n",
        "            time += time_quantum\n",
        "            process.remaining_time -= time_quantum\n",
        "            queue.append(process)\n",
        "        else:\n",
        "            time += process.remaining_time\n",
        "            process.waiting_time = time - process.burst_time\n",
        "            process.turnaround_time = time\n",
        "            process.remaining_time = 0\n",
        "\n",
        "def print_scheduling_result(processes):\n",
        "    \"\"\"\n",
        "    Function to print the scheduling result.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    total_waiting_time = 0\n",
        "    total_turnaround_time = 0\n",
        "\n",
        "    print(\"PID\\tBurst Time\\tWaiting Time\\tTurnaround Time\")\n",
        "    for process in processes:\n",
        "        total_waiting_time += process.waiting_time\n",
        "        total_turnaround_time += process.turnaround_time\n",
        "        print(f\"{process.pid}\\t{process.burst_time}\\t\\t{process.waiting_time}\\t\\t{process.turnaround_time}\")\n",
        "\n",
        "    print(f\"\\nAverage Waiting Time: {total_waiting_time / len(processes):.2f}\")\n",
        "    print(f\"Average Turnaround Time: {total_turnaround_time / len(processes):.2f}\")\n",
        "\n",
        "# Example usage\n",
        "process_list = [Process(1, 10), Process(2, 5), Process(3, 8)]\n",
        "time_quantum = 2\n",
        "round_robin_scheduling(process_list, time_quantum)\n",
        "print_scheduling_result(process_list)"
      ],
      "metadata": {
        "id": "ztB1K_2B7-c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shortest Remaining Time First"
      ],
      "metadata": {
        "id": "WbeRuywQ8CKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Process:\n",
        "    def __init__(self, pid, arrival_time, burst_time):\n",
        "        self.pid = pid\n",
        "        self.arrival_time = arrival_time\n",
        "        self.burst_time = burst_time\n",
        "        self.remaining_time = burst_time\n",
        "        self.waiting_time = 0\n",
        "        self.turnaround_time = 0\n",
        "\n",
        "def shortest_remaining_time_first(processes):\n",
        "    \"\"\"\n",
        "    Function to perform Shortest Remaining Time First (SRTF) Scheduling.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None (modifies the processes list in place)\n",
        "    \"\"\"\n",
        "    time = 0\n",
        "    completed = 0\n",
        "    n = len(processes)\n",
        "    processes.sort(key=lambda x: x.arrival_time)\n",
        "    current_process = None\n",
        "\n",
        "    while completed != n:\n",
        "        # Find the process with the shortest remaining time at the current time\n",
        "        eligible_processes = [p for p in processes if p.arrival_time <= time and p.remaining_time > 0]\n",
        "        if eligible_processes:\n",
        "            current_process = min(eligible_processes, key=lambda x: x.remaining_time)\n",
        "        else:\n",
        "            time += 1\n",
        "            continue\n",
        "\n",
        "        # Execute the current process for 1 time unit\n",
        "        current_process.remaining_time -= 1\n",
        "        time += 1\n",
        "\n",
        "        # If the process is completed\n",
        "        if current_process.remaining_time == 0:\n",
        "            completed += 1\n",
        "            current_process.waiting_time = time - current_process.arrival_time - current_process.burst_time\n",
        "            current_process.turnaround_time = time - current_process.arrival_time\n",
        "\n",
        "def print_scheduling_result(processes):\n",
        "    \"\"\"\n",
        "    Function to print the scheduling result.\n",
        "\n",
        "    Args:\n",
        "    processes: List of Process objects\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    total_waiting_time = 0\n",
        "    total_turnaround_time = 0\n",
        "\n",
        "    print(\"PID\\tArrival Time\\tBurst Time\\tWaiting Time\\tTurnaround Time\")\n",
        "    for process in processes:\n",
        "        total_waiting_time += process.waiting_time\n",
        "        total_turnaround_time += process.turnaround_time\n",
        "        print(f\"{process.pid}\\t{process.arrival_time}\\t\\t{process.burst_time}\\t\\t{process.waiting_time}\\t\\t{process.turnaround_time}\")\n",
        "\n",
        "    print(f\"\\nAverage Waiting Time: {total_waiting_time / len(processes):.2f}\")\n",
        "    print(f\"Average Turnaround Time: {total_turnaround_time / len(processes):.2f}\")\n",
        "\n",
        "# Example usage\n",
        "process_list = [Process(1, 0, 6), Process(2, 2, 8), Process(3, 4, 7), Process(4, 6, 3)]\n",
        "shortest_remaining_time_first(process_list)\n",
        "print_scheduling_result(process_list)"
      ],
      "metadata": {
        "id": "O4Sp055f8CfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Work-Conserving Multiprocessor Scheduling"
      ],
      "metadata": {
        "id": "lbf6eriS8cRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Task:\n",
        "    def __init__(self, tid, priority):\n",
        "        self.tid = tid\n",
        "        self.priority = priority\n",
        "\n",
        "class Processor:\n",
        "    def __init__(self, pid):\n",
        "        self.pid = pid\n",
        "        self.is_idle = True\n",
        "\n",
        "def work_conserving(tasks, processors):\n",
        "    \"\"\"\n",
        "    Work-Conserving Multiprocessor Scheduling algorithm.\n",
        "\n",
        "    Args:\n",
        "    tasks: List of Task objects\n",
        "    processors: List of Processor objects\n",
        "\n",
        "    Returns:\n",
        "    A list of assignments (task, processor) tuples\n",
        "    \"\"\"\n",
        "    assignments = []\n",
        "\n",
        "    while tasks:\n",
        "        # Select task with highest priority\n",
        "        task = max(tasks, key=lambda t: t.priority)\n",
        "        tasks.remove(task)\n",
        "\n",
        "        # Select idle processor\n",
        "        processor = next((p for p in processors if p.is_idle), None)\n",
        "\n",
        "        if processor:\n",
        "            # Assign task to processor\n",
        "            assignments.append((task, processor))\n",
        "            processor.is_idle = False\n",
        "        else:\n",
        "            # If no idle processor is available, break the loop\n",
        "            break\n",
        "\n",
        "    return assignments\n",
        "\n",
        "# Example usage\n",
        "tasks = [Task(1, 10), Task(2, 5), Task(3, 8)]\n",
        "processors = [Processor(1), Processor(2)]\n",
        "\n",
        "assignments = work_conserving(tasks, processors)\n",
        "for task, processor in assignments:\n",
        "    print(f\"Task {task.tid} with priority {task.priority} assigned to Processor {processor.pid}\")"
      ],
      "metadata": {
        "id": "eEvtluYw8crM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rate-Monotonic Scheduling"
      ],
      "metadata": {
        "id": "maJbOhqV8fsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Task:\n",
        "    def __init__(self, tid, execution_time, period):\n",
        "        self.tid = tid\n",
        "        self.execution_time = execution_time\n",
        "        self.period = period\n",
        "        self.remaining_time = execution_time\n",
        "\n",
        "def rate_monotonic_scheduling(tasks, total_time):\n",
        "    \"\"\"\n",
        "    Rate-Monotonic Scheduling algorithm.\n",
        "\n",
        "    Args:\n",
        "    tasks: List of Task objects\n",
        "    total_time: Total time for the scheduling simulation\n",
        "\n",
        "    Returns:\n",
        "    A schedule as a list of (time, task_id) tuples\n",
        "    \"\"\"\n",
        "    schedule = []\n",
        "\n",
        "    for time in range(total_time):\n",
        "        # Select the task with the shortest period (highest priority)\n",
        "        highest_priority_task = None\n",
        "        for task in tasks:\n",
        "            if task.remaining_time > 0 and (highest_priority_task is None or task.period < highest_priority_task.period):\n",
        "                highest_priority_task = task\n",
        "\n",
        "        if highest_priority_task:\n",
        "            # Execute the highest priority task\n",
        "            schedule.append((time, highest_priority_task.tid))\n",
        "            highest_priority_task.remaining_time -= 1\n",
        "\n",
        "            # Check if the task is completed\n",
        "            if highest_priority_task.remaining_time == 0:\n",
        "                highest_priority_task.remaining_time = highest_priority_task.execution_time\n",
        "\n",
        "        # Check for task period reset\n",
        "        for task in tasks:\n",
        "            if time % task.period == 0:\n",
        "                task.remaining_time = task.execution_time if task.remaining_time == 0 else task.remaining_time\n",
        "\n",
        "    return schedule\n",
        "\n",
        "# Example usage\n",
        "tasks = [Task(1, 1, 4), Task(2, 2, 6), Task(3, 1, 8)]\n",
        "total_time = 20\n",
        "\n",
        "schedule = rate_monotonic_scheduling(tasks, total_time)\n",
        "for time, task_id in schedule:\n",
        "    print(f\"Time {time}: Task {task_id}\")"
      ],
      "metadata": {
        "id": "zfDMNvpN8gE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilevel Feedback Queue (MLFQ) Scheduling Algorithm"
      ],
      "metadata": {
        "id": "NatEpqkZ8_0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Thread:\n",
        "    def __init__(self, tid, burst_time):\n",
        "        self.tid = tid\n",
        "        self.burst_time = burst_time\n",
        "        self.remaining_time = burst_time\n",
        "        self.priority = 0\n",
        "        self.finished = False\n",
        "\n",
        "    def execute(self, time_quantum):\n",
        "        execution_time = min(self.remaining_time, time_quantum)\n",
        "        self.remaining_time -= execution_time\n",
        "        if self.remaining_time == 0:\n",
        "            self.finished = True\n",
        "        return execution_time\n",
        "\n",
        "class MLFQ:\n",
        "    def __init__(self, num_queues, time_quantums):\n",
        "        self.queues = [[] for _ in range(num_queues)]\n",
        "        self.time_quantums = time_quantums\n",
        "        self.num_queues = num_queues\n",
        "\n",
        "    def initialize_queues(self, threads):\n",
        "        for thread in threads:\n",
        "            self.queues[0].append(thread)\n",
        "\n",
        "    def all_empty(self):\n",
        "        return all(not queue for queue in self.queues)\n",
        "\n",
        "    def adjust_priority(self, thread):\n",
        "        if thread.priority < self.num_queues - 1:\n",
        "            thread.priority += 1\n",
        "        self.queues[thread.priority].append(thread)\n",
        "\n",
        "    def execute(self, thread):\n",
        "        time_quantum = self.time_quantums[thread.priority]\n",
        "        execution_time = thread.execute(time_quantum)\n",
        "        return execution_time\n",
        "\n",
        "    def run(self):\n",
        "        while not self.all_empty():\n",
        "            for queue in self.queues:\n",
        "                if queue:\n",
        "                    thread = queue.pop(0)\n",
        "                    self.execute(thread)\n",
        "                    if not thread.finished:\n",
        "                        self.adjust_priority(thread)\n",
        "\n",
        "# Example usage\n",
        "threads = [Thread(1, 10), Thread(2, 5), Thread(3, 7)]\n",
        "num_queues = 3\n",
        "time_quantums = [2, 4, 8]\n",
        "\n",
        "mlfq = MLFQ(num_queues, time_quantums)\n",
        "mlfq.initialize_queues(threads)\n",
        "mlfq.run()"
      ],
      "metadata": {
        "id": "nGypJ-sW9AKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shortest Seek Time First (SSTF) Scheduling Algorithm"
      ],
      "metadata": {
        "id": "OB7CU1Bw9EQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SSTF:\n",
        "    def __init__(self, requests, initial_head_position):\n",
        "        self.requests = requests\n",
        "        self.head_position = initial_head_position\n",
        "        self.total_seek_time = 0\n",
        "        self.seek_sequence = []\n",
        "\n",
        "    def shortest_seek_time_first(self):\n",
        "        while self.requests:\n",
        "            closest_request = min(self.requests, key=lambda x: abs(x - self.head_position))\n",
        "            self.requests.remove(closest_request)\n",
        "            self.seek_sequence.append(closest_request)\n",
        "            self.total_seek_time += abs(closest_request - self.head_position)\n",
        "            self.head_position = closest_request\n",
        "\n",
        "    def get_seek_sequence(self):\n",
        "        return self.seek_sequence\n",
        "\n",
        "    def get_total_seek_time(self):\n",
        "        return self.total_seek_time\n",
        "\n",
        "# Example usage\n",
        "requests = [100, 50, 10, 75, 30]\n",
        "initial_head_position = 50\n",
        "\n",
        "sstf = SSTF(requests, initial_head_position)\n",
        "sstf.shortest_seek_time_first()\n",
        "print(\"Seek Sequence:\", sstf.get_seek_sequence())\n",
        "print(\"Total Seek Time:\", sstf.get_total_seek_time())"
      ],
      "metadata": {
        "id": "oW_fc7hK9EmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Johnson's Rule"
      ],
      "metadata": {
        "id": "5kNA7TvH9R8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def johnsons_rule(jobs):\n",
        "    \"\"\"\n",
        "    Apply Johnson's Rule to schedule jobs on two machines.\n",
        "\n",
        "    Args:\n",
        "        jobs: List of tuples where each tuple contains (job_id, machine1_time, machine2_time).\n",
        "\n",
        "    Returns:\n",
        "        List of job_ids in the order they should be scheduled.\n",
        "    \"\"\"\n",
        "    left_sequence = []\n",
        "    right_sequence = []\n",
        "\n",
        "    while jobs:\n",
        "        # Find the job with the minimum processing time\n",
        "        min_job = min(jobs, key=lambda x: min(x[1], x[2]))\n",
        "        jobs.remove(min_job)\n",
        "\n",
        "        # If the minimum processing time is on machine 1, add the job to the left sequence\n",
        "        if min_job[1] < min_job[2]:\n",
        "            left_sequence.append(min_job[0])\n",
        "        # If the minimum processing time is on machine 2, add the job to the right sequence\n",
        "        else:\n",
        "            right_sequence.insert(0, min_job[0])\n",
        "\n",
        "    return left_sequence + right_sequence\n",
        "\n",
        "# Example usage\n",
        "jobs = [\n",
        "    (1, 2, 5),  # (job_id, machine1_time, machine2_time)\n",
        "    (2, 3, 1),\n",
        "    (3, 5, 2),\n",
        "    (4, 4, 3)\n",
        "]\n",
        "\n",
        "schedule = johnsons_rule(jobs)\n",
        "print(\"Optimal job schedule:\", schedule)"
      ],
      "metadata": {
        "id": "_KocDqi49SPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Least Loaded Algorithm"
      ],
      "metadata": {
        "id": "z7xJ0cVL9lDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "def least_loaded_algorithm(tasks, num_processors):\n",
        "    \"\"\"\n",
        "    Schedule tasks using the Least Loaded Algorithm.\n",
        "\n",
        "    Args:\n",
        "        tasks: List of tuples where each tuple contains (task_id, task_load).\n",
        "        num_processors: Number of available processors.\n",
        "\n",
        "    Returns:\n",
        "        List of lists where each sublist contains the tasks assigned to a processor.\n",
        "    \"\"\"\n",
        "    # Initialize a min-heap to store processors and their current loads\n",
        "    processors = [(0, i) for i in range(num_processors)]  # (current_load, processor_id)\n",
        "    heapq.heapify(processors)\n",
        "\n",
        "    # Initialize the assignment list\n",
        "    assignment = [[] for _ in range(num_processors)]\n",
        "\n",
        "    # Assign tasks to processors\n",
        "    for task_id, task_load in tasks:\n",
        "        # Get the processor with the least load\n",
        "        current_load, processor_id = heapq.heappop(processors)\n",
        "\n",
        "        # Assign the task to the processor\n",
        "        assignment[processor_id].append(task_id)\n",
        "\n",
        "        # Update the processor's load and push it back into the heap\n",
        "        heapq.heappush(processors, (current_load + task_load, processor_id))\n",
        "\n",
        "    return assignment\n",
        "\n",
        "# Example usage\n",
        "tasks = [\n",
        "    (1, 5),  # (task_id, task_load)\n",
        "    (2, 3),\n",
        "    (3, 8),\n",
        "    (4, 2),\n",
        "    (5, 7)\n",
        "]\n",
        "num_processors = 3\n",
        "\n",
        "schedule = least_loaded_algorithm(tasks, num_processors)\n",
        "print(\"Task assignment to processors:\", schedule)"
      ],
      "metadata": {
        "id": "ngbeOWtp9lgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max-Min Algorithm"
      ],
      "metadata": {
        "id": "4IeqJWSC-PaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Task:\n",
        "    def __init__(self, task_id, requirements):\n",
        "        self.task_id = task_id\n",
        "        self.requirements = requirements\n",
        "\n",
        "class Resource:\n",
        "    def __init__(self, resource_id, available_capacity):\n",
        "        self.resource_id = resource_id\n",
        "        self.available_capacity = available_capacity\n",
        "        self.assigned_tasks = []\n",
        "\n",
        "    def assign_task(self, task):\n",
        "        self.assigned_tasks.append(task.task_id)\n",
        "        self.available_capacity -= task.requirements\n",
        "\n",
        "def max_min_scheduling(tasks, resources):\n",
        "    # Sort tasks based on their requirements in descending order\n",
        "    tasks.sort(key=lambda t: t.requirements, reverse=True)\n",
        "    # Sort resources based on their available capacity in ascending order\n",
        "    resources.sort(key=lambda r: r.available_capacity)\n",
        "\n",
        "    for task in tasks:\n",
        "        # Select the resource with the maximum available capacity\n",
        "        resource = max(resources, key=lambda r: r.available_capacity)\n",
        "        # Assign the task to the selected resource\n",
        "        resource.assign_task(task)\n",
        "\n",
        "    return resources\n",
        "\n",
        "# Example usage\n",
        "tasks = [\n",
        "    Task(1, 10),  # (task_id, requirements)\n",
        "    Task(2, 20),\n",
        "    Task(3, 5),\n",
        "    Task(4, 15)\n",
        "]\n",
        "resources = [\n",
        "    Resource(1, 25),  # (resource_id, available_capacity)\n",
        "    Resource(2, 30),\n",
        "    Resource(3, 10)\n",
        "]\n",
        "\n",
        "allocated_resources = max_min_scheduling(tasks, resources)\n",
        "\n",
        "# Print the task assignments\n",
        "for resource in allocated_resources:\n",
        "    print(f\"Resource {resource.resource_id} assigned tasks: {resource.assigned_tasks} with remaining capacity: {resource.available_capacity}\")"
      ],
      "metadata": {
        "id": "0LJupoKN-Puj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Fit Decreasing (FFD) Algorithm"
      ],
      "metadata": {
        "id": "xjzeKgQN-SOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Task:\n",
        "    def __init__(self, task_id, requirements):\n",
        "        self.task_id = task_id\n",
        "        self.requirements = requirements\n",
        "\n",
        "    def fits(self, vm):\n",
        "        return self.requirements <= vm.available_capacity\n",
        "\n",
        "class VM:\n",
        "    def __init__(self, vm_id, available_capacity):\n",
        "        self.vm_id = vm_id\n",
        "        self.available_capacity = available_capacity\n",
        "        self.assigned_tasks = []\n",
        "\n",
        "    def assign_task(self, task):\n",
        "        self.assigned_tasks.append(task.task_id)\n",
        "        self.available_capacity -= task.requirements\n",
        "\n",
        "def ffd(tasks, vms):\n",
        "    # Sort tasks based on their requirements in descending order\n",
        "    tasks.sort(key=lambda t: t.requirements, reverse=True)\n",
        "\n",
        "    for task in tasks:\n",
        "        for vm in vms:\n",
        "            if task.fits(vm):\n",
        "                vm.assign_task(task)\n",
        "                break\n",
        "\n",
        "    return vms\n",
        "\n",
        "# Example usage\n",
        "tasks = [\n",
        "    Task(1, 10),  # (task_id, requirements)\n",
        "    Task(2, 20),\n",
        "    Task(3, 5),\n",
        "    Task(4, 15)\n",
        "]\n",
        "vms = [\n",
        "    VM(1, 25),  # (vm_id, available_capacity)\n",
        "    VM(2, 30),\n",
        "    VM(3, 10)\n",
        "]\n",
        "\n",
        "allocated_vms = ffd(tasks, vms)\n",
        "\n",
        "# Print the task assignments\n",
        "for vm in allocated_vms:\n",
        "    print(f\"VM {vm.vm_id} assigned tasks: {vm.assigned_tasks} with remaining capacity: {vm.available_capacity}\")"
      ],
      "metadata": {
        "id": "7AvaNvz0-SlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weighted Fair Queuing algorithm"
      ],
      "metadata": {
        "id": "ge3AllJT-n-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "class Packet:\n",
        "    def __init__(self, packet_id, arrival_time, length, weight):\n",
        "        self.packet_id = packet_id\n",
        "        self.arrival_time = arrival_time\n",
        "        self.length = length\n",
        "        self.weight = weight\n",
        "        self.start_time = 0\n",
        "        self.finish_time = 0\n",
        "\n",
        "class WFQScheduler:\n",
        "    def __init__(self):\n",
        "        self.virtual_time = 0\n",
        "        self.queue = []\n",
        "        self.flow_last_finish_time = {}\n",
        "\n",
        "    def enqueue(self, packet):\n",
        "        flow_id = packet.packet_id  # Assuming packet_id as flow_id for simplicity\n",
        "        if flow_id in self.flow_last_finish_time:\n",
        "            packet.start_time = max(self.virtual_time, self.flow_last_finish_time[flow_id])\n",
        "        else:\n",
        "            packet.start_time = self.virtual_time\n",
        "\n",
        "        packet.finish_time = packet.start_time + (packet.length / packet.weight)\n",
        "        self.flow_last_finish_time[flow_id] = packet.finish_time\n",
        "\n",
        "        heapq.heappush(self.queue, (packet.finish_time, packet))\n",
        "\n",
        "    def dequeue(self):\n",
        "        if not self.queue:\n",
        "            return None\n",
        "\n",
        "        finish_time, packet = heapq.heappop(self.queue)\n",
        "        self.virtual_time = max(self.virtual_time, finish_time)\n",
        "        return packet\n",
        "\n",
        "def weighted_fair_queuing(packets):\n",
        "    scheduler = WFQScheduler()\n",
        "\n",
        "    # Enqueue packets\n",
        "    for packet in packets:\n",
        "        scheduler.enqueue(packet)\n",
        "\n",
        "    # Dequeue packets in WFQ order\n",
        "    scheduled_packets = []\n",
        "    while True:\n",
        "        packet = scheduler.dequeue()\n",
        "        if packet is None:\n",
        "            break\n",
        "        scheduled_packets.append(packet)\n",
        "\n",
        "    return scheduled_packets\n",
        "\n",
        "# Example usage\n",
        "packets = [\n",
        "    Packet(1, 0, 1000, 1),  # (packet_id, arrival_time, length, weight)\n",
        "    Packet(2, 1, 2000, 2),\n",
        "    Packet(3, 2, 1500, 1),\n",
        "    Packet(4, 3, 2500, 3)\n",
        "]\n",
        "\n",
        "scheduled_packets = weighted_fair_queuing(packets)\n",
        "\n",
        "for packet in scheduled_packets:\n",
        "    print(f\"Packet {packet.packet_id} scheduled with start time {packet.start_time} and finish time {packet.finish_time}\")"
      ],
      "metadata": {
        "id": "p8Rz8AAd-o0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Max-Min Fairness"
      ],
      "metadata": {
        "id": "9qFJMwNC-v6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def max_min_fairness(demands, total_bandwidth):\n",
        "    n = len(demands)\n",
        "    allocation = np.full(n, total_bandwidth / n)\n",
        "    converged = False\n",
        "\n",
        "    while not converged:\n",
        "        converged = True\n",
        "        deficit = demands - allocation\n",
        "\n",
        "        for i in range(n):\n",
        "            if deficit[i] > 0:\n",
        "                allocation[i] += deficit[i] / np.sum(deficit > 0)\n",
        "                converged = False\n",
        "\n",
        "        allocation = np.minimum(allocation, demands)\n",
        "        remaining_bandwidth = total_bandwidth - np.sum(allocation)\n",
        "        allocation += remaining_bandwidth / n\n",
        "\n",
        "    return allocation\n",
        "\n",
        "# Example usage\n",
        "demands = np.array([5, 10, 15, 20])\n",
        "total_bandwidth = 30\n",
        "allocation = max_min_fairness(demands, total_bandwidth)\n",
        "print(\"Bandwidth allocation:\", allocation)"
      ],
      "metadata": {
        "id": "KLRbjjfN-yKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token Bucket Algorithm"
      ],
      "metadata": {
        "id": "ptZUMI9Q-3Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class TokenBucket:\n",
        "    def __init__(self, capacity, refill_rate):\n",
        "        self.capacity = capacity\n",
        "        self.tokens = capacity\n",
        "        self.refill_rate = refill_rate\n",
        "        self.last_refill_time = time.time()\n",
        "\n",
        "    def refill(self):\n",
        "        now = time.time()\n",
        "        time_passed = now - self.last_refill_time\n",
        "        tokens_to_add = time_passed * self.refill_rate\n",
        "        self.tokens = min(self.capacity, self.tokens + tokens_to_add)\n",
        "        self.last_refill_time = now\n",
        "\n",
        "    def consume(self, tokens_required):\n",
        "        self.refill()\n",
        "        if self.tokens >= tokens_required:\n",
        "            self.tokens -= tokens_required\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "def token_bucket_algorithm(packets, capacity, refill_rate):\n",
        "    bucket = TokenBucket(capacity, refill_rate)\n",
        "    for packet in packets:\n",
        "        if bucket.consume(packet['size']):\n",
        "            print(f\"Transmitting packet: {packet}\")\n",
        "        else:\n",
        "            print(f\"Dropping packet: {packet}\")\n",
        "\n",
        "# Example usage\n",
        "packets = [{'size': 1}, {'size': 1}, {'size': 1}, {'size': 1}, {'size': 1}]\n",
        "capacity = 3\n",
        "refill_rate = 1  # tokens per second\n",
        "token_bucket_algorithm(packets, capacity, refill_rate)"
      ],
      "metadata": {
        "id": "mXDJmScU-3mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Earliest Due Date (EDD) Algorithm"
      ],
      "metadata": {
        "id": "u7v4cTle_Ert"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def earliest_due_date(jobs):\n",
        "    # Sort jobs by their due dates in non-decreasing order\n",
        "    jobs.sort(key=lambda job: job['due_date'])\n",
        "\n",
        "    # Initialize the current time\n",
        "    current_time = 0\n",
        "\n",
        "    # Schedule jobs in the earliest available time slot\n",
        "    schedule = []\n",
        "    for job in jobs:\n",
        "        schedule.append((current_time, job))\n",
        "        current_time += job['processing_time']\n",
        "\n",
        "    return schedule\n",
        "\n",
        "# Example usage\n",
        "jobs = [\n",
        "    {'id': 1, 'processing_time': 2, 'due_date': 5},\n",
        "    {'id': 2, 'processing_time': 1, 'due_date': 3},\n",
        "    {'id': 3, 'processing_time': 3, 'due_date': 8},\n",
        "    {'id': 4, 'processing_time': 2, 'due_date': 4}\n",
        "]\n",
        "\n",
        "schedule = earliest_due_date(jobs)\n",
        "for start_time, job in schedule:\n",
        "    print(f\"Job {job['id']} starts at time {start_time} and is due by {job['due_date']}\")"
      ],
      "metadata": {
        "id": "s-PUr702_FHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Minimum Completion Time (MCT) Algorithm"
      ],
      "metadata": {
        "id": "VO9hD8S5_UYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mct_algorithm(tasks, resources):\n",
        "    # Sort tasks by their processing time in non-decreasing order\n",
        "    tasks.sort(key=lambda x: x['processing_time'])\n",
        "\n",
        "    # Assign each task to the resource that minimizes its completion time\n",
        "    for task in tasks:\n",
        "        min_completion_time = float('inf')\n",
        "        selected_resource = None\n",
        "        for resource in resources:\n",
        "            completion_time = calculate_completion_time(task, resource)\n",
        "            if completion_time < min_completion_time:\n",
        "                min_completion_time = completion_time\n",
        "                selected_resource = resource\n",
        "        assign_task_to_resource(task, selected_resource)\n",
        "\n",
        "def calculate_completion_time(task, resource):\n",
        "    # Placeholder for actual completion time calculation logic\n",
        "    return task['processing_time'] + resource['available_time']\n",
        "\n",
        "def assign_task_to_resource(task, resource):\n",
        "    # Placeholder for task assignment logic\n",
        "    resource['available_time'] += task['processing_time']\n",
        "    print(f\"Assigned task {task['id']} to resource {resource['id']}\")\n",
        "\n",
        "# Example usage\n",
        "tasks = [\n",
        "    {'id': 1, 'processing_time': 5},\n",
        "    {'id': 2, 'processing_time': 2},\n",
        "    {'id': 3, 'processing_time': 8},\n",
        "    {'id': 4, 'processing_time': 3}\n",
        "]\n",
        "\n",
        "resources = [\n",
        "    {'id': 1, 'available_time': 0},\n",
        "    {'id': 2, 'available_time': 0}\n",
        "]\n",
        "\n",
        "mct_algorithm(tasks, resources)"
      ],
      "metadata": {
        "id": "IcYEU28M_UuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Predictive Control (MPC) algorithm for dynamic scheduling in a smart grid"
      ],
      "metadata": {
        "id": "VR50sGvG_jTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.optimize as opt\n",
        "\n",
        "class SmartGridMPC:\n",
        "    def __init__(self, horizon, timestep, demand_forecast, generation_forecast, storage_capacity, storage_init, max_charge_rate, max_discharge_rate):\n",
        "        self.horizon = horizon\n",
        "        self.timestep = timestep\n",
        "        self.demand_forecast = demand_forecast\n",
        "        self.generation_forecast = generation_forecast\n",
        "        self.storage_capacity = storage_capacity\n",
        "        self.storage_init = storage_init\n",
        "        self.max_charge_rate = max_charge_rate\n",
        "        self.max_discharge_rate = max_discharge_rate\n",
        "\n",
        "    def mpc_optimization(self):\n",
        "        # Define the number of steps\n",
        "        n_steps = int(self.horizon / self.timestep)\n",
        "\n",
        "        # Initial state of the storage\n",
        "        storage_state = self.storage_init\n",
        "\n",
        "        # Objective function to minimize\n",
        "        def objective(x):\n",
        "            return np.sum(x[:n_steps])  # Minimize the cost of purchasing electricity\n",
        "\n",
        "        # Constraints\n",
        "        constraints = []\n",
        "\n",
        "        # Storage state constraints\n",
        "        for t in range(n_steps):\n",
        "            constraints.append({'type': 'ineq', 'fun': lambda x, t=t: self.storage_capacity - (storage_state + np.sum(x[n_steps + t*2: n_steps + (t+1)*2]))})  # Storage capacity limit\n",
        "            constraints.append({'type': 'ineq', 'fun': lambda x, t=t: storage_state + np.sum(x[n_steps + t*2: n_steps + (t+1)*2])})  # Non-negative storage\n",
        "            storage_state += x[n_steps + t*2] - x[n_steps + t*2 + 1]\n",
        "\n",
        "        # Power balance constraints\n",
        "        for t in range(n_steps):\n",
        "            constraints.append({'type': 'eq', 'fun': lambda x, t=t: self.demand_forecast[t] - self.generation_forecast[t] - x[t] - (x[n_steps + t*2] - x[n_steps + t*2 + 1])})\n",
        "\n",
        "        # Charge and discharge rate limits\n",
        "        for t in range(n_steps):\n",
        "            constraints.append({'type': 'ineq', 'fun': lambda x, t=t: self.max_charge_rate - x[n_steps + t*2]})\n",
        "            constraints.append({'type': 'ineq', 'fun': lambda x, t=t: self.max_discharge_rate - x[n_steps + t*2 + 1]})\n",
        "\n",
        "        # Initial guess\n",
        "        x0 = np.zeros(3 * n_steps)\n",
        "\n",
        "        # Optimization\n",
        "        result = opt.minimize(objective, x0, constraints=constraints)\n",
        "        return result.x[:n_steps]\n",
        "\n",
        "    def execute(self):\n",
        "        optimal_schedule = self.mpc_optimization()\n",
        "        return optimal_schedule\n",
        "\n",
        "# Example usage\n",
        "horizon = 24  # 24 hours\n",
        "timestep = 1  # 1 hour\n",
        "demand_forecast = np.random.uniform(50, 150, horizon)  # Random demand forecast\n",
        "generation_forecast = np.random.uniform(50, 150, horizon)  # Random generation forecast\n",
        "storage_capacity = 500  # 500 kWh\n",
        "storage_init = 100  # Initial storage level\n",
        "max_charge_rate = 50  # 50 kWh/h\n",
        "max_discharge_rate = 50  # 50 kWh/h\n",
        "\n",
        "mpc = SmartGridMPC(horizon, timestep, demand_forecast, generation_forecast, storage_capacity, storage_init, max_charge_rate, max_discharge_rate)\n",
        "optimal_schedule = mpc.execute()\n",
        "print(\"Optimal schedule:\", optimal_schedule)"
      ],
      "metadata": {
        "id": "OJvFo1Ur_jpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reinforcement Learning (RL) algorithm for adaptive scheduling in an autonomous system"
      ],
      "metadata": {
        "id": "T7HL8u3__xWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "class RLAdaptiveScheduling:\n",
        "    def __init__(self, num_states, num_actions, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "        self.num_states = num_states\n",
        "        self.num_actions = num_actions\n",
        "        self.alpha = alpha  # Learning rate\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "        self.q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "    def select_action(self, state):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.choice(self.num_actions)  # Explore\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state])  # Exploit\n",
        "\n",
        "    def update_q_value(self, state, action, reward, next_state):\n",
        "        best_next_action = np.argmax(self.q_table[next_state])\n",
        "        td_target = reward + self.gamma * self.q_table[next_state, best_next_action]\n",
        "        td_error = td_target - self.q_table[state, action]\n",
        "        self.q_table[state, action] += self.alpha * td_error\n",
        "\n",
        "    def simulate_environment(self, state, action):\n",
        "        \"\"\"\n",
        "        Simulates the environment. For simplicity, this example assumes a toy environment.\n",
        "        Replace this with the actual environment dynamics.\n",
        "        \"\"\"\n",
        "        next_state = (state + action) % self.num_states  # Example transition\n",
        "        reward = -1 if action == 0 else 1  # Example reward\n",
        "        return next_state, reward\n",
        "\n",
        "    def train(self, num_episodes):\n",
        "        for episode in range(num_episodes):\n",
        "            state = np.random.randint(0, self.num_states)  # Initialize state randomly\n",
        "            done = False\n",
        "            while not done:\n",
        "                action = self.select_action(state)\n",
        "                next_state, reward = self.simulate_environment(state, action)\n",
        "                self.update_q_value(state, action, reward, next_state)\n",
        "                state = next_state\n",
        "                if next_state == self.num_states - 1:  # Example termination condition\n",
        "                    done = True\n",
        "\n",
        "    def get_optimal_policy(self):\n",
        "        return np.argmax(self.q_table, axis=1)\n",
        "\n",
        "# Example usage\n",
        "num_states = 10  # Number of states in the environment\n",
        "num_actions = 4  # Number of possible actions\n",
        "rl_agent = RLAdaptiveScheduling(num_states, num_actions)\n",
        "rl_agent.train(num_episodes=1000)\n",
        "optimal_policy = rl_agent.get_optimal_policy()\n",
        "print(\"Optimal policy:\", optimal_policy)"
      ],
      "metadata": {
        "id": "QgdRjtFr_xte"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
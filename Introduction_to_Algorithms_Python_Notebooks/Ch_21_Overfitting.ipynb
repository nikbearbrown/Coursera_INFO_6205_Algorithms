{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial Regression with Regularization"
      ],
      "metadata": {
        "id": "r4XM_7ReIOKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKSZZXPyH_3q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "X_train = np.linspace(0, 10, 100).reshape(-1, 1)\n",
        "y_train = 2 * np.sin(X_train) + np.random.normal(0, 0.5, size=X_train.shape)\n",
        "\n",
        "# Generate polynomial features\n",
        "poly = PolynomialFeatures(degree=10)\n",
        "X_poly_train = poly.fit_transform(X_train)\n",
        "\n",
        "# Fit polynomial regression with regularization\n",
        "ridge = Ridge(alpha=1.0)\n",
        "ridge.fit(X_poly_train, y_train)\n",
        "\n",
        "# Evaluate model performance\n",
        "train_error = mean_squared_error(y_train, ridge.predict(X_poly_train))\n",
        "print(f\"Training Error: {train_error}\")\n",
        "\n",
        "# Optionally, repeat the above steps for test data\n",
        "# X_test = np.linspace(0, 10, 50).reshape(-1, 1)\n",
        "# y_test = 2 * np.sin(X_test) + np.random.normal(0, 0.5, size=X_test.shape)\n",
        "# X_poly_test = poly.transform(X_test)\n",
        "# test_error = mean_squared_error(y_test, ridge.predict(X_poly_test))\n",
        "# print(f\"Test Error: {test_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost-Complexity Pruning"
      ],
      "metadata": {
        "id": "hfI69axKIgoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load example dataset (Boston housing dataset)\n",
        "data = load_boston()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor\n",
        "reg = DecisionTreeRegressor(random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the original tree\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_tree(reg, filled=True, feature_names=data.feature_names)\n",
        "plt.title(\"Original Decision Tree\")\n",
        "plt.show()\n",
        "\n",
        "# Cost-Complexity Pruning: Path to optimal alpha\n",
        "path = reg.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "# Train Decision Trees for each alpha and collect accuracy\n",
        "regs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    reg = DecisionTreeRegressor(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    reg.fit(X_train, y_train)\n",
        "    regs.append(reg)\n",
        "\n",
        "# Remove the last element in regs and ccp_alphas, which is the trivial tree with ccp_alpha=0.0\n",
        "regs = regs[:-1]\n",
        "ccp_alphas = ccp_alphas[:-1]\n",
        "\n",
        "# Mean Squared Error vs alpha for training and testing sets\n",
        "train_errors = [mean_squared_error(y_train, reg.predict(X_train)) for reg in regs]\n",
        "test_errors = [mean_squared_error(y_test, reg.predict(X_test)) for reg in regs]\n",
        "\n",
        "# Plot Mean Squared Error vs alpha\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ccp_alphas, train_errors, marker='o', label='train', drawstyle=\"steps-post\")\n",
        "plt.plot(ccp_alphas, test_errors, marker='o', label='test', drawstyle=\"steps-post\")\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "plt.title(\"Mean Squared Error vs alpha for training and testing sets\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "abji6XZaIg6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Maintenance"
      ],
      "metadata": {
        "id": "pmRG4UnEI0sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate noisy data\n",
        "np.random.seed(0)\n",
        "X = np.linspace(0, 10, 100)\n",
        "y_true = np.sin(X) + np.random.normal(0, 0.1, size=X.shape)\n",
        "\n",
        "# Fit polynomial regression models of different degrees\n",
        "degrees = [1, 4, 15]\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i, degree in enumerate(degrees):\n",
        "    plt.subplot(1, len(degrees), i + 1)\n",
        "    plt.scatter(X, y_true, s=10, label='Noisy data')\n",
        "    coeffs = np.polyfit(X, y_true, degree)\n",
        "    poly = np.poly1d(coeffs)\n",
        "    y_pred = poly(X)\n",
        "    plt.plot(X, y_pred, color='r', label=f'Degree {degree}')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('y')\n",
        "    plt.title(f'Polynomial Regression: Degree {degree}')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VnuBoH-UI2wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression for Stock Price Prediction"
      ],
      "metadata": {
        "id": "TpfVstIJI7bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load historical stock price data (example)\n",
        "# Replace with your actual dataset or API call to fetch data\n",
        "# Here's a simulated example with random data\n",
        "np.random.seed(0)\n",
        "dates = pd.date_range('2023-01-01', periods=100)\n",
        "prices = np.cumsum(np.random.randn(100))  # Simulated stock prices\n",
        "data = pd.DataFrame({'Date': dates, 'Price': prices})\n",
        "data.set_index('Date', inplace=True)\n",
        "\n",
        "# Feature engineering: Create lagged features for prediction\n",
        "data['Price_Lag1'] = data['Price'].shift(1)\n",
        "data['Price_Lag2'] = data['Price'].shift(2)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Prepare data for regression\n",
        "X = data[['Price_Lag1', 'Price_Lag2']].values\n",
        "y = data['Price'].values\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Initialize and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n",
        "print(f'R-squared: {r2:.2f}')\n",
        "\n",
        "# Plotting predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(data.index[-len(y_test):], y_test, label='Actual Prices')\n",
        "plt.plot(data.index[-len(y_test):], y_pred, label='Predicted Prices')\n",
        "plt.title('Stock Price Prediction using Linear Regression')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j2vCtR4_I7vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold Cross-Validation"
      ],
      "metadata": {
        "id": "DXgcYXQ7JZJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load or generate your dataset\n",
        "# For demonstration, let's use a synthetic dataset\n",
        "np.random.seed(0)\n",
        "X = np.random.randn(100, 5)  # Example features\n",
        "y = np.random.randn(100)     # Example target\n",
        "\n",
        "# Initialize KFold with k=5\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
        "\n",
        "# Initialize a model (e.g., Linear Regression)\n",
        "model = LinearRegression()\n",
        "\n",
        "# Lists to store scores\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "# Perform K-Fold Cross-Validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split data into train and test folds\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Fit the model on training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on training data\n",
        "    train_pred = model.predict(X_train)\n",
        "    train_error = mean_squared_error(y_train, train_pred)\n",
        "    train_scores.append(train_error)\n",
        "\n",
        "    # Evaluate on test data\n",
        "    test_pred = model.predict(X_test)\n",
        "    test_error = mean_squared_error(y_test, test_pred)\n",
        "    test_scores.append(test_error)\n",
        "\n",
        "# Calculate average scores\n",
        "avg_train_score = np.mean(train_scores)\n",
        "avg_test_score = np.mean(test_scores)\n",
        "\n",
        "print(f'Average Train MSE: {avg_train_score:.2f}')\n",
        "print(f'Average Test MSE: {avg_test_score:.2f}')"
      ],
      "metadata": {
        "id": "T-ER3J0nJZ4L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
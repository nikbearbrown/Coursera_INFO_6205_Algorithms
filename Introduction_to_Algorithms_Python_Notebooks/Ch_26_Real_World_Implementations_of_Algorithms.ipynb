{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PageRank Algorithm"
      ],
      "metadata": {
        "id": "lVxi3RxTosXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vovQe1q3ooGi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def pagerank(links, d=0.85, max_iterations=100, tolerance=1e-5):\n",
        "    \"\"\"\n",
        "    Calculate PageRank for web pages based on link structure.\n",
        "\n",
        "    Parameters:\n",
        "    - links: Dictionary where keys are page IDs and values are lists of outgoing links.\n",
        "    - d: Damping factor (typically 0.85).\n",
        "    - max_iterations: Maximum number of iterations for convergence.\n",
        "    - tolerance: Convergence threshold (stop iteration when changes are below this threshold).\n",
        "\n",
        "    Returns:\n",
        "    - pageranks: Dictionary where keys are page IDs and values are PageRank scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize variables\n",
        "    N = len(links)  # Number of pages\n",
        "    pageranks = {page: 1 / N for page in links}  # Initialize PageRank scores\n",
        "    convergence = False\n",
        "\n",
        "    # Iteration until convergence or max_iterations\n",
        "    for _ in range(max_iterations):\n",
        "        new_pageranks = {page: (1 - d) / N for page in links}  # Initialize new PageRank scores\n",
        "\n",
        "        for page in links:\n",
        "            for q in links[page]:\n",
        "                new_pageranks[q] += d * pageranks[page] / len(links[page])\n",
        "\n",
        "        # Check convergence\n",
        "        max_diff = max(abs(new_pageranks[page] - pageranks[page]) for page in links)\n",
        "        if max_diff < tolerance:\n",
        "            convergence = True\n",
        "            break\n",
        "\n",
        "        pageranks = new_pageranks  # Update PageRank scores\n",
        "\n",
        "    if not convergence:\n",
        "        print(\"Warning: PageRank algorithm did not converge within the specified number of iterations.\")\n",
        "\n",
        "    return pageranks\n",
        "\n",
        "# Example usage\n",
        "links = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['A'],\n",
        "    'C': ['A', 'B'],\n",
        "}\n",
        "\n",
        "pageranks = pagerank(links)\n",
        "print(\"PageRank scores:\")\n",
        "for page, score in pageranks.items():\n",
        "    print(f\"{page}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quicksort Algorithm For Sorting Employees by Salary"
      ],
      "metadata": {
        "id": "9RbDuaSnowuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Employee:\n",
        "    def __init__(self, name, salary):\n",
        "        self.name = name\n",
        "        self.salary = salary\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.name}: {self.salary}\"\n",
        "\n",
        "def quicksort_employees(employees):\n",
        "    if len(employees) <= 1:\n",
        "        return employees\n",
        "\n",
        "    pivot = employees[len(employees) // 2].salary\n",
        "    left = [emp for emp in employees if emp.salary < pivot]\n",
        "    middle = [emp for emp in employees if emp.salary == pivot]\n",
        "    right = [emp for emp in employees if emp.salary > pivot]\n",
        "\n",
        "    return quicksort_employees(left) + middle + quicksort_employees(right)\n",
        "\n",
        "# Example usage\n",
        "employees = [\n",
        "    Employee(\"Alice\", 60000),\n",
        "    Employee(\"Bob\", 45000),\n",
        "    Employee(\"Charlie\", 75000),\n",
        "    Employee(\"David\", 55000),\n",
        "    Employee(\"Eve\", 80000)\n",
        "]\n",
        "\n",
        "sorted_employees = quicksort_employees(employees)\n",
        "print(\"Sorted employees by salary:\")\n",
        "for emp in sorted_employees:\n",
        "    print(emp)"
      ],
      "metadata": {
        "id": "Cl2fjK49oydF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secure Data Transmission"
      ],
      "metadata": {
        "id": "3qRBRwCto0qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sympy  # for prime number generation\n",
        "\n",
        "def generate_rsa_keys():\n",
        "    # Step 1: Choose two distinct prime numbers p and q\n",
        "    p = sympy.randprime(2**15, 2**16)\n",
        "    q = sympy.randprime(2**15, 2**16)\n",
        "\n",
        "    # Step 2: Compute n = pq and φ = (p-1)(q-1)\n",
        "    n = p * q\n",
        "    phi = (p - 1) * (q - 1)\n",
        "\n",
        "    # Step 3: Choose an integer e such that 1 < e < φ and gcd(e, φ) = 1\n",
        "    e = random.randrange(2, phi)\n",
        "    while sympy.gcd(e, phi) != 1:\n",
        "        e = random.randrange(2, phi)\n",
        "\n",
        "    # Step 4: Compute the private key d such that ed ≡ 1 (mod φ)\n",
        "    d = sympy.mod_inverse(e, phi)\n",
        "\n",
        "    # Public key (n, e) and private key (n, d)\n",
        "    public_key = (n, e)\n",
        "    private_key = (n, d)\n",
        "\n",
        "    return public_key, private_key\n",
        "\n",
        "def encrypt(message, public_key):\n",
        "    n, e = public_key\n",
        "    # Step 6: Encrypt message M to ciphertext C: C ≡ M^e (mod n)\n",
        "    ciphertext = pow(message, e, n)\n",
        "    return ciphertext\n",
        "\n",
        "def decrypt(ciphertext, private_key):\n",
        "    n, d = private_key\n",
        "    # Step 7: Decrypt ciphertext C to get original message M: M ≡ C^d (mod n)\n",
        "    message = pow(ciphertext, d, n)\n",
        "    return message\n",
        "\n",
        "# Example usage\n",
        "public_key, private_key = generate_rsa_keys()\n",
        "print(\"Public Key (n, e):\", public_key)\n",
        "print(\"Private Key (n, d):\", private_key)\n",
        "\n",
        "message = 123456789  # Example message to encrypt\n",
        "print(\"Original Message:\", message)\n",
        "\n",
        "# Encrypt message using the public key\n",
        "ciphertext = encrypt(message, public_key)\n",
        "print(\"Encrypted:\", ciphertext)\n",
        "\n",
        "# Decrypt the ciphertext using the private key\n",
        "decrypted_message = decrypt(ciphertext, private_key)\n",
        "print(\"Decrypted Message:\", decrypted_message)"
      ],
      "metadata": {
        "id": "PywtVrEko2dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest For House Price Prediction"
      ],
      "metadata": {
        "id": "tlFifdTPo4l0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def random_forest_regression(D, N):\n",
        "    # Step 1: Initialize an empty list T\n",
        "    T = []\n",
        "\n",
        "    # Step 2: Loop over the number of trees N\n",
        "    for i in range(N):\n",
        "        # Step 3: Sample a bootstrap dataset D_i from D\n",
        "        bootstrap_indices = np.random.choice(len(D), size=len(D), replace=True)\n",
        "        D_i = D[bootstrap_indices]\n",
        "\n",
        "        # Step 4: Train a decision tree T_i on D_i\n",
        "        tree = DecisionTreeRegressor()\n",
        "        X_i = D_i[:, :-1]  # Features (all columns except the last one which is the target)\n",
        "        y_i = D_i[:, -1]   # Target (last column)\n",
        "        tree.fit(X_i, y_i)\n",
        "\n",
        "        # Step 5: Append T_i to T\n",
        "        T.append(tree)\n",
        "\n",
        "    # Step 6: Random Forest model RF is the list of trees T\n",
        "    RF = T\n",
        "\n",
        "    return RF\n",
        "\n",
        "# Example usage\n",
        "# Assuming D is your training dataset where the last column is the target (house prices)\n",
        "# D = np.array([[feature1, feature2, ..., price], [feature1, feature2, ..., price], ...])\n",
        "# N is the number of trees in the forest\n",
        "\n",
        "# Example usage:\n",
        "# RF = random_forest_regression(D, N)"
      ],
      "metadata": {
        "id": "yTIK9tLXo6Vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-means Clustering"
      ],
      "metadata": {
        "id": "Z76BrYMZo8p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def kmeans(X, K, max_iters=100):\n",
        "    # Step 1: Randomly initialize K centroids C\n",
        "    centroids = X[np.random.choice(len(X), size=K, replace=False)]\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        # Step 2: Assign each data point to the nearest centroid\n",
        "        distances = np.sqrt(((X - centroids[:, np.newaxis])**2).sum(axis=2))\n",
        "        cluster_assignments = np.argmin(distances, axis=0)\n",
        "\n",
        "        # Step 3: Update each centroid as the mean of the data points assigned to it\n",
        "        for k in range(K):\n",
        "            centroids[k] = np.mean(X[cluster_assignments == k], axis=0)\n",
        "\n",
        "    # Step 4: Return cluster centroids C and cluster assignments A\n",
        "    return centroids, cluster_assignments\n",
        "\n",
        "# Example usage:\n",
        "# X is your data points in the form of a numpy array, where each row is a data point\n",
        "# K is the number of clusters you want to find\n",
        "\n",
        "# Example:\n",
        "# centroids, assignments = kmeans(X, K)\n",
        "# centroids contains the final centroids of the clusters\n",
        "# assignments contains the cluster assignment for each data point in X"
      ],
      "metadata": {
        "id": "0p_WxxW9o-ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# t-SNE"
      ],
      "metadata": {
        "id": "_wRMPE0GpAWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def compute_pairwise_affinities(X, perplexity=30.0):\n",
        "    # Step 3: Compute pairwise affinities P_{ij} using Gaussian kernel\n",
        "    distances = pairwise_distances(X, metric='euclidean', squared=True)\n",
        "    P = np.zeros_like(distances)\n",
        "    sigmas = np.std(distances, axis=1)\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        denom = 2.0 * (sigmas[i] ** 2)\n",
        "        distances[i, i] = np.inf\n",
        "        p = np.exp(-distances[i] / denom)\n",
        "        P[i] = p / np.sum(p)\n",
        "\n",
        "    P = (P + P.T) / (2.0 * len(X))\n",
        "    return P\n",
        "\n",
        "def t_sne(X, perplexity=30.0, n_iter=1000, learning_rate=200.0):\n",
        "    # Step 4: Initialize low-dimensional embeddings Y randomly\n",
        "    Y = np.random.normal(0, 0.0001, (len(X), 2))\n",
        "\n",
        "    # Step 5: Iterate for a number of iterations\n",
        "    for t in range(n_iter):\n",
        "        # Step 6: Compute Q_{ij} using low-dimensional embeddings Y\n",
        "        distances = pairwise_distances(Y, metric='euclidean', squared=True)\n",
        "        inv_distances = 1.0 / (1.0 + distances)\n",
        "        np.fill_diagonal(inv_distances, 0)\n",
        "        Q = inv_distances / np.sum(inv_distances)\n",
        "\n",
        "        # Step 7: Compute gradient ∂C/∂y_i using gradient descent\n",
        "        PQ_diff = compute_pairwise_affinities(X) - Q\n",
        "        grad = np.zeros_like(Y)\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            grad[i] = 4 * np.sum((PQ_diff[:, i] * inv_distances[:, i])[:, np.newaxis] * (Y[i] - Y), axis=0)\n",
        "\n",
        "        # Step 8: Update embeddings Y\n",
        "        Y -= learning_rate * grad\n",
        "\n",
        "        # Step 9: Normalize Y\n",
        "        Y -= np.mean(Y, axis=0)\n",
        "        Y /= np.std(Y, axis=0)\n",
        "\n",
        "    # Step 10: Return low-dimensional embeddings Y\n",
        "    return Y\n",
        "\n",
        "# Example usage:\n",
        "# X is your high-dimensional data points in the form of a numpy array, where each row is a data point\n",
        "# perplexity is the perplexity parameter for t-SNE\n",
        "# n_iter is the number of iterations to run the optimization\n",
        "# learning_rate is the learning rate for gradient descent\n",
        "\n",
        "# Example:\n",
        "# X = np.random.rand(100, 50)  # Example data with 100 data points of dimension 50\n",
        "# Y = t_sne(X, perplexity=30.0, n_iter=1000, learning_rate=200.0)\n",
        "# print(Y)"
      ],
      "metadata": {
        "id": "bPh9HiPTpBz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Three-Way Merge Algorithm"
      ],
      "metadata": {
        "id": "7-KjwXuipDv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(base, modified, other):\n",
        "    result = []\n",
        "    i, j, k = 0, 0, 0\n",
        "    len_base, len_modified, len_other = len(base), len(modified), len(other)\n",
        "\n",
        "    while i < len_modified or j < len_other:\n",
        "        if i < len_modified and j < len_other and modified[i] == other[j]:\n",
        "            result.append(modified[i])\n",
        "            i += 1\n",
        "            j += 1\n",
        "        elif i < len_modified and k < len_base and modified[i] == base[k]:\n",
        "            result.append(other[j])\n",
        "            i += 1\n",
        "            j += 1\n",
        "        elif j < len_other and k < len_base and other[j] == base[k]:\n",
        "            result.append(modified[i])\n",
        "            i += 1\n",
        "            j += 1\n",
        "        else:\n",
        "            # Conflict resolution logic can be added here\n",
        "            result.append(\"<<<<<<<\")\n",
        "            result.append(base[k])\n",
        "            result.append(\"=======\")\n",
        "            result.append(modified[i])\n",
        "            result.append(\">>>>>>>\")\n",
        "            i += 1\n",
        "            j += 1\n",
        "        k += 1\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "base = [\"Hello\", \"world\", \"!\", \"This\", \"is\", \"a\", \"test\"]\n",
        "modified = [\"Hello\", \"world\", \"!\", \"This\", \"is\", \"an\", \"example\"]\n",
        "other = [\"Hello\", \"world\", \"!\", \"This\", \"is\", \"another\", \"test\"]\n",
        "\n",
        "merged_result = merge(base, modified, other)\n",
        "for line in merged_result:\n",
        "    print(line)"
      ],
      "metadata": {
        "id": "pHHSxT4ppFEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A* Algorithm"
      ],
      "metadata": {
        "id": "7OqhPWSWpIpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic(node, goal):\n",
        "    \"\"\"\n",
        "    Heuristic function to estimate the cost from the current node to the goal.\n",
        "    This function should be defined based on the specific problem.\n",
        "    \"\"\"\n",
        "    # Example heuristic: Euclidean distance, Manhattan distance, etc.\n",
        "    pass\n",
        "\n",
        "def reconstruct_path(goal):\n",
        "    \"\"\"\n",
        "    Function to reconstruct the path from start to goal.\n",
        "    This function should be defined to trace back the path from goal to start.\n",
        "    \"\"\"\n",
        "    # Example reconstruction logic\n",
        "    pass\n",
        "\n",
        "def astar_algorithm(graph, start, goal):\n",
        "    \"\"\"\n",
        "    A* algorithm to find the shortest path in a weighted graph.\n",
        "\n",
        "    Args:\n",
        "    graph: A dictionary representing the graph where keys are nodes and values are dictionaries\n",
        "           of neighboring nodes with edge weights.\n",
        "    start: The starting node.\n",
        "    goal: The goal node.\n",
        "\n",
        "    Returns:\n",
        "    The shortest path from start to goal.\n",
        "    \"\"\"\n",
        "    open_list = {start}  # Set of nodes to be evaluated\n",
        "    explored = set()  # Set of nodes already evaluated\n",
        "\n",
        "    # Initialize the cost from start to each node with infinity\n",
        "    g = {node: float('inf') for node in graph}\n",
        "    g[start] = 0  # Cost from start to start is 0\n",
        "\n",
        "    # Initialize the heuristic cost estimate from each node to the goal\n",
        "    h = {node: heuristic(node, goal) for node in graph}\n",
        "\n",
        "    while open_list:\n",
        "        # Current node is the node with the lowest f(n) = g(n) + h(n)\n",
        "        current = min(open_list, key=lambda node: g[node] + h[node])\n",
        "        open_list.remove(current)\n",
        "        explored.add(current)\n",
        "\n",
        "        if current == goal:\n",
        "            return reconstruct_path(goal)  # Path found\n",
        "\n",
        "        # For each neighbor of the current node\n",
        "        for neighbor in graph[current]:\n",
        "            if neighbor not in explored:\n",
        "                tentative_g = g[current] + graph[current][neighbor]\n",
        "                if tentative_g < g.get(neighbor, float('inf')):\n",
        "                    g[neighbor] = tentative_g\n",
        "                    open_list.add(neighbor)\n",
        "\n",
        "    return None  # Path not found\n",
        "\n",
        "# Example usage:\n",
        "# Define the graph as an adjacency list with edge weights\n",
        "graph = {\n",
        "    'A': {'B': 1, 'C': 3},\n",
        "    'B': {'A': 1, 'D': 1, 'E': 5},\n",
        "    'C': {'A': 3, 'F': 12},\n",
        "    'D': {'B': 1, 'E': 1},\n",
        "    'E': {'B': 5, 'D': 1, 'F': 2},\n",
        "    'F': {'C': 12, 'E': 2}\n",
        "}\n",
        "\n",
        "# Define the heuristic function and path reconstruction function appropriately\n",
        "def heuristic(node, goal):\n",
        "    # Example heuristic: Manhattan distance for grid-based graph\n",
        "    heuristics = {\n",
        "        'A': 7,\n",
        "        'B': 6,\n",
        "        'C': 2,\n",
        "        'D': 1,\n",
        "        'E': 0,\n",
        "        'F': 3\n",
        "    }\n",
        "    return heuristics.get(node, float('inf'))\n",
        "\n",
        "def reconstruct_path(goal):\n",
        "    # Example reconstruction logic\n",
        "    return [\"Path to goal\"]  # Placeholder\n",
        "\n",
        "start_node = 'A'\n",
        "goal_node = 'F'\n",
        "shortest_path = astar_algorithm(graph, start_node, goal_node)\n",
        "print(\"Shortest Path:\", shortest_path)"
      ],
      "metadata": {
        "id": "jB15cKo7pJLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round Robin Scheduling"
      ],
      "metadata": {
        "id": "PQTaqkz4pLCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "class Process:\n",
        "    def __init__(self, name, arrival_time, burst_time):\n",
        "        self.name = name\n",
        "        self.arrival_time = arrival_time\n",
        "        self.burst_time = burst_time\n",
        "        self.remaining_time = burst_time\n",
        "\n",
        "    def execute(self, time_slice):\n",
        "        if self.remaining_time <= time_slice:\n",
        "            time_executed = self.remaining_time\n",
        "            self.remaining_time = 0\n",
        "        else:\n",
        "            time_executed = time_slice\n",
        "            self.remaining_time -= time_slice\n",
        "        return time_executed\n",
        "\n",
        "def round_robin(processes, time_slice):\n",
        "    queue = deque()\n",
        "    current_time = 0\n",
        "    total_processes = len(processes)\n",
        "    index = 0\n",
        "    while index < total_processes or queue:\n",
        "        while index < total_processes and processes[index].arrival_time <= current_time:\n",
        "            queue.append(processes[index])\n",
        "            index += 1\n",
        "\n",
        "        if not queue:\n",
        "            current_time = processes[index].arrival_time if index < total_processes else current_time\n",
        "        else:\n",
        "            current_process = queue.popleft()\n",
        "            time_executed = current_process.execute(time_slice)\n",
        "            current_time += time_executed\n",
        "\n",
        "            if current_process.remaining_time > 0:\n",
        "                queue.append(current_process)\n",
        "\n",
        "    print(\"Process\\t\\tTurnaround Time\")\n",
        "    total_turnaround_time = 0\n",
        "    for process in processes:\n",
        "        turnaround_time = process.arrival_time + process.burst_time\n",
        "        total_turnaround_time += turnaround_time\n",
        "        print(f\"{process.name}\\t\\t{turnaround_time}\")\n",
        "\n",
        "    average_turnaround_time = total_turnaround_time / total_processes\n",
        "    print(f\"\\nAverage Turnaround Time: {average_turnaround_time}\")\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    processes = [\n",
        "        Process(\"P1\", 0, 8),\n",
        "        Process(\"P2\", 1, 4),\n",
        "        Process(\"P3\", 2, 9),\n",
        "        Process(\"P4\", 3, 5),\n",
        "    ]\n",
        "    time_slice = 3\n",
        "    round_robin(processes, time_slice)"
      ],
      "metadata": {
        "id": "NUMoUxaMpMcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EdgeRank Algorithm"
      ],
      "metadata": {
        "id": "O75if81RpQz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def calculate_affinity(user, post):\n",
        "    # Placeholder function for calculating affinity score\n",
        "    return random.uniform(0, 1)\n",
        "\n",
        "def calculate_edge_weight(interaction_type):\n",
        "    # Placeholder function for calculating edge weight based on interaction type\n",
        "    return random.uniform(0, 1)\n",
        "\n",
        "def calculate_time_decay(current_time, post_time):\n",
        "    # Placeholder function for calculating time decay based on time difference\n",
        "    return random.uniform(0, 1)\n",
        "\n",
        "def compute_edge_rank(posts, current_time):\n",
        "    for post in posts:\n",
        "        affinity_score = calculate_affinity(post['user'], post)\n",
        "        edge_weight = calculate_edge_weight(post['interaction_type'])\n",
        "        time_decay = calculate_time_decay(current_time, post['time'])\n",
        "        edge_rank_score = affinity_score * edge_weight * time_decay\n",
        "        post['edge_rank_score'] = edge_rank_score\n",
        "\n",
        "    # Sort posts by EdgeRank score in descending order\n",
        "    sorted_posts = sorted(posts, key=lambda x: x['edge_rank_score'], reverse=True)\n",
        "    return sorted_posts\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Example data: list of posts with user, interaction type, time\n",
        "    posts = [\n",
        "        {'user': 'User1', 'interaction_type': 'Like', 'time': 10},\n",
        "        {'user': 'User2', 'interaction_type': 'Comment', 'time': 5},\n",
        "        {'user': 'User3', 'interaction_type': 'Share', 'time': 15},\n",
        "    ]\n",
        "    current_time = 20  # Assuming current time\n",
        "\n",
        "    # Compute EdgeRank scores for posts and sort them\n",
        "    ranked_posts = compute_edge_rank(posts, current_time)\n",
        "\n",
        "    # Print sorted list of posts by EdgeRank score\n",
        "    for idx, post in enumerate(ranked_posts):\n",
        "        print(f\"Rank {idx+1}: User '{post['user']}' with EdgeRank Score {post['edge_rank_score']:.3f}\")"
      ],
      "metadata": {
        "id": "dc2NGTELpQ72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grover's Algorithm"
      ],
      "metadata": {
        "id": "OuEBDImopTD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the oracle function marking the target state\n",
        "def oracle(target_state, state):\n",
        "    if state == target_state:\n",
        "        return -1  # Apply phase flip\n",
        "    else:\n",
        "        return 1   # No change to state\n",
        "\n",
        "# Define the diffusion operator\n",
        "def diffusion_operator(state_vector):\n",
        "    N = len(state_vector)\n",
        "    mean = np.mean(state_vector)\n",
        "    return 2 * mean - state_vector\n",
        "\n",
        "# Initialize the system to the equal superposition state\n",
        "def initialize_superposition(N):\n",
        "    return np.ones(N) / np.sqrt(N)\n",
        "\n",
        "# Apply Grover's algorithm iteration\n",
        "def grover_iteration(state_vector, target_state, oracle_func, diffusion_func):\n",
        "    # Apply oracle\n",
        "    for i in range(len(state_vector)):\n",
        "        state_vector[i] *= oracle_func(target_state, i)\n",
        "\n",
        "    # Apply diffusion operator\n",
        "    state_vector = diffusion_func(state_vector)\n",
        "\n",
        "    return state_vector\n",
        "\n",
        "# Grover's algorithm\n",
        "def grover_algorithm(N, target_state, num_iterations):\n",
        "    # Initialize state to equal superposition\n",
        "    state_vector = initialize_superposition(N)\n",
        "\n",
        "    # Perform Grover iterations\n",
        "    for _ in range(num_iterations):\n",
        "        state_vector = grover_iteration(state_vector, target_state, oracle, diffusion_operator)\n",
        "\n",
        "    # Measure the final state\n",
        "    measured_state = np.argmax(state_vector)\n",
        "\n",
        "    return measured_state\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    N = 8  # Number of states\n",
        "    target_state = 3  # Target state to be found\n",
        "    num_iterations = 2  # Number of iterations (O(sqrt(N)))\n",
        "\n",
        "    # Run Grover's algorithm\n",
        "    result = grover_algorithm(N, target_state, num_iterations)\n",
        "\n",
        "    print(f\"Target state {target_state} found at index {result}\")"
      ],
      "metadata": {
        "id": "WFvmUkGqpUjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q-Learning Algorithm"
      ],
      "metadata": {
        "id": "kwGsSDMIpWxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Q-Learning function\n",
        "def q_learning(env, num_episodes, alpha, gamma, epsilon):\n",
        "    # Initialize Q table arbitrarily\n",
        "    Q = np.zeros((env.num_states, env.num_actions))\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        # Reset the environment, observe initial state\n",
        "        s = env.reset()\n",
        "\n",
        "        # Episode terminates when done is True\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            # Choose action using epsilon-greedy policy derived from Q\n",
        "            if np.random.rand() < epsilon:\n",
        "                a = np.random.randint(env.num_actions)\n",
        "            else:\n",
        "                a = np.argmax(Q[s])\n",
        "\n",
        "            # Take action, observe reward and next state\n",
        "            s_prime, r, done, _ = env.step(a)\n",
        "\n",
        "            # Update Q table\n",
        "            Q[s, a] = Q[s, a] + alpha * (r + gamma * np.max(Q[s_prime]) - Q[s, a])\n",
        "\n",
        "            # Move to next state\n",
        "            s = s_prime\n",
        "\n",
        "    return Q\n",
        "\n",
        "# Example environment\n",
        "class ExampleEnvironment:\n",
        "    def __init__(self):\n",
        "        self.num_states = 5\n",
        "        self.num_actions = 3\n",
        "\n",
        "    def reset(self):\n",
        "        return np.random.randint(self.num_states)\n",
        "\n",
        "    def step(self, action):\n",
        "        next_state = np.random.randint(self.num_states)\n",
        "        reward = np.random.randn()  # Reward as a random number\n",
        "        done = np.random.rand() < 0.2  # 20% chance of termination\n",
        "        return next_state, reward, done, {}\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    env = ExampleEnvironment()\n",
        "    num_episodes = 1000\n",
        "    alpha = 0.1  # Learning rate\n",
        "    gamma = 0.9  # Discount factor\n",
        "    epsilon = 0.1  # Epsilon for epsilon-greedy policy\n",
        "\n",
        "    Q = q_learning(env, num_episodes, alpha, gamma, epsilon)\n",
        "\n",
        "    print(\"Q table after learning:\")\n",
        "    print(Q)"
      ],
      "metadata": {
        "id": "HBAPARwypX3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Needleman-Wunsch Algorithm"
      ],
      "metadata": {
        "id": "tovH5QuVpaNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Needleman-Wunsch algorithm function\n",
        "def needleman_wunsch(seq1, seq2, gap_penalty, match_score, mismatch_penalty):\n",
        "    len_seq1 = len(seq1)\n",
        "    len_seq2 = len(seq2)\n",
        "\n",
        "    # Initialize the score matrix\n",
        "    F = np.zeros((len_seq1 + 1, len_seq2 + 1))\n",
        "\n",
        "    # Initialize the first row and column with gap penalties\n",
        "    for i in range(1, len_seq1 + 1):\n",
        "        F[i, 0] = i * gap_penalty\n",
        "\n",
        "    for j in range(1, len_seq2 + 1):\n",
        "        F[0, j] = j * gap_penalty\n",
        "\n",
        "    # Fill the score matrix using the recurrence relation\n",
        "    for i in range(1, len_seq1 + 1):\n",
        "        for j in range(1, len_seq2 + 1):\n",
        "            match = F[i-1, j-1] + (match_score if seq1[i-1] == seq2[j-1] else mismatch_penalty)\n",
        "            delete = F[i-1, j] + gap_penalty\n",
        "            insert = F[i, j-1] + gap_penalty\n",
        "            F[i, j] = max(match, delete, insert)\n",
        "\n",
        "    # Perform traceback to find the optimal alignment\n",
        "    align1, align2 = [], []\n",
        "    i, j = len_seq1, len_seq2\n",
        "\n",
        "    while i > 0 and j > 0:\n",
        "        if F[i, j] == F[i-1, j-1] + (match_score if seq1[i-1] == seq2[j-1] else mismatch_penalty):\n",
        "            align1.append(seq1[i-1])\n",
        "            align2.append(seq2[j-1])\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        elif F[i, j] == F[i-1, j] + gap_penalty:\n",
        "            align1.append(seq1[i-1])\n",
        "            align2.append('-')\n",
        "            i -= 1\n",
        "        else:\n",
        "            align1.append('-')\n",
        "            align2.append(seq2[j-1])\n",
        "            j -= 1\n",
        "\n",
        "    while i > 0:\n",
        "        align1.append(seq1[i-1])\n",
        "        align2.append('-')\n",
        "        i -= 1\n",
        "\n",
        "    while j > 0:\n",
        "        align1.append('-')\n",
        "        align2.append(seq2[j-1])\n",
        "        j -= 1\n",
        "\n",
        "    align1.reverse()\n",
        "    align2.reverse()\n",
        "\n",
        "    return ''.join(align1), ''.join(align2), F[len_seq1, len_seq2]\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    seq1 = \"AGTACGCA\"\n",
        "    seq2 = \"TATGC\"\n",
        "    gap_penalty = -2\n",
        "    match_score = 1\n",
        "    mismatch_penalty = -1\n",
        "\n",
        "    aligned_seq1, aligned_seq2, score = needleman_wunsch(seq1, seq2, gap_penalty, match_score, mismatch_penalty)\n",
        "\n",
        "    print(f\"Optimal Alignment Score: {score}\")\n",
        "    print(f\"Optimal Alignment:\")\n",
        "    print(aligned_seq1)\n",
        "    print(aligned_seq2)"
      ],
      "metadata": {
        "id": "ySEb0Irspbny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent Algorithm"
      ],
      "metadata": {
        "id": "wmQsbRkJpd5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Gradient Descent function\n",
        "def gradient_descent(theta, alpha, gradient_func, max_iterations=1000, tolerance=1e-5):\n",
        "    iteration = 0\n",
        "    while iteration < max_iterations:\n",
        "        gradient = gradient_func(theta)\n",
        "        if np.linalg.norm(gradient) < tolerance:\n",
        "            break\n",
        "        theta = theta - alpha * gradient\n",
        "        iteration += 1\n",
        "    return theta\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example objective function J(theta) and its gradient function\n",
        "    def J(theta):\n",
        "        return np.sum(theta ** 2)  # Example objective function: sum of squares\n",
        "\n",
        "    def gradient_J(theta):\n",
        "        return 2 * theta  # Gradient of the objective function: 2 * theta\n",
        "\n",
        "    # Initialize parameters theta\n",
        "    initial_theta = np.array([3.0, 4.0])\n",
        "    learning_rate = 0.1\n",
        "\n",
        "    # Apply gradient descent\n",
        "    final_theta = gradient_descent(initial_theta, learning_rate, gradient_J)\n",
        "\n",
        "    # Output the result\n",
        "    print(f\"Initial theta: {initial_theta}\")\n",
        "    print(f\"Final theta after gradient descent: {final_theta}\")\n"
      ],
      "metadata": {
        "id": "k2WyZVnjpgJQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}